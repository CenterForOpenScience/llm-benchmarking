=== GENERATED PROMPT ===

You are an information verifier.
You are given a json object and a reference document, your task is to score the information (key, value pair) presented in the extraced JSON object based on the information presented in the reference document.

=== START OF EXPLANATION OF WHAT EACH FIELD IN THE JSON MEAN ===
{
  "original_study": {
    "claim": {
      "hypotheses": "A testable hypothesis based on the claim",
      "hypotheses_location": "Specific location where the hypotheses is stated in the original paper",
      "statement": "The main claim made by the original study that matches the claim given as an input.",
      "statement_location": "Specific location where the claim is stated in the original paper.",
      "study_type": "Type of study (Experimental, Observational, Meta-Analysis)"
    },
    "data": {
      "source": "Data Source (e.g., survey, database)",
      "wave_or_subset": "Specific waves or subsets (if applicable)",
      "sample_size": "Sample size of the selected data (if applicable)",
      "unit_of_analysis": "Unit of analysis (e.g., individual, household)",
      "access_details": "Access details (e.g., restrictions, request process)",
      "notes": "Any additional information or caveats (e.g., encoding issues, nested structure, missing metadata, unusual column formats)"
    },
    "method": {
      "description": "Narrative summary of how the study was conducted.",
      "steps": "Ordered list of procedural steps to reproduce the study.",
      "models": "Models or statistical approach (e.g., regression type)",
      "outcome_variable": "Dependent/outcome variable measured or analyzed",
      "independent_variables": "Primary variables expected to influence the outcome",
      "control_variables": "Variables controlled for in the analysis",
      "tools_software": "Tools or software specifics (e.g., mentions of R, Python, packages)"
    },
    "results": {
      "summary": "Narrative summary of the main results or findings from the original study.",
      "numerical_results": [
        {
          "outcome_name": "Name or label of the outcome (e.g., 'test_score', 'conversion_rate')",
          "value": "Numeric result value (e.g., 0.45)",
          "unit": "Optional unit of measurement (e.g., %, points, ms)",
          "effect_size": "Optional effect size (e.g., Cohen's d, odds ratio)",
          "confidence_interval": {
            "lower": "Lower bound (e.g., 0.32)",
            "upper": "Upper bound (e.g., 0.58)",
            "level": "Confidence level, e.g., 95"
          },
          "p_value": "Optional p-value associated with the result (e.g., 0.001)",
          "statistical_significance": "Boolean indicating if result is statistically significant",
          "direction": "Qualitative direction of the effect (positive, negative, or null) based on the sign and magnitude of the reported result."
        }
      ]
    },
    "metadata": {
      "original_paper_id": "DOI or unique identifier.",
      "original_paper_title": "Title of the original paper.",
      "original_paper_code": "Link to the original study's codebase.",
      "original_paper_data": "Link to the original study's dataset(s)."
    }
  }
}
=== END OF EXPLANATION OF WHAT EACH FIELD IN THE JSON MEAN ===

Follow the rubrics below for your evaluation of each component in the JSON. The rubric uses a 0-3 scoring scale for all components, where:
- 3: Exact Match – The extracted information is identical or nearly identical to the reference in the document. The meaning is preserved completely, with the same level of detail, including all key elements (e.g., variables, relationships, or numerical values). No omissions or additions of unrelated information. 
- 2: Mostly Similar – The extracted information conveys the same core meaning as the reference, but with different phrasing or structure. Minor details may be omitted, but the essential information is preserved. If the extracted content is a finding that directly supports a hypothesis, consider it equivalent. 
- 1: Loosely Related – The extracted information has partial overlap with the reference but includes significant differences, omissions of major details, or additions of unrelated information. The core meaning is somewhat preserved but incomplete or altered.
- 0: No Match – No relevant overlap with the reference, completely incorrect, or missing entirely.
- NA: The reference document does not contain information to evaluate this component/field of the JSON.

=== START OF EXTRACTED JSON TO BE EVALUATED START ===
    {
  "lang": "python",
  "entry": "main.py",
  "python_packages": [
    "pandas==2.1.4",
    "numpy==1.26.4",
    "scikit-learn==1.3.2",
    "statsmodels==0.14.1",
    "pyreadstat==1.2.6"
  ]
}
=== END OF EXTRACTED JSON TO BE EVALUATED END ===
    
=== START OF REFERENCE DOCUMENT WITH THE CORRECT INFO ===
    Data-Analytic Replication of a Research
Claim from Andrews & Money (2009),
from the British Journal of Political
Science
[Project types supported: Data Analytic Replication, Source Data Reproduction, Author Data
Reproduction, Robustness, Generalizability]
SCORE report Andrews_BritJournPoliSci_2009_Ryq7_95my
Review information for this preregistration is available here.
Welcome to the replication/reproduction team! You can get started with your preregistration by
clicking here.
CONFIDENTIALITY DISCLAIMER: Other teams are making predictions about the outcomes of
many different studies, not knowing which studies have been selected for replication. As a
consequence, the success of this project requires full confidentiality of the research process,
including peer review. This includes privacy about which studies have been selected for
replication and all aspects of the discussion about these replication designs.

Review Information
Review period: 06/14/2022 - 06/16/2022
Editor: Nathaniel Porter
Reviewer 1: Cristina Zogmaister
Reviewer 2: Hansika Kapoor
Completion sign off dates:
Editor: 2022-06-16
Reviewer 1: June 16th, 2022(please date when satisfied with this review)
Reviewer 2: June 16th 2022
View-only links to: Original Paper, Replication Materials

Instructions for Data Analysts
The preregistration for this replication study was started by a separate team of researchers who were
responsible for identifying data sources and constructing them into a replication dataset(s) for your use in
the analysis. They have completed sections 1-13 of the preregistration below, and included additional
materials in the OSF project that document how the dataset was constructed.
In cases where all of the underlying data sources were able to be freely shared and posted, the
constructed dataset(s) have been posted to the OSF as well, which you are free to use in designing the
analysis plan (see below for details). In cases where some or all of the data sources could not be freely
shared or posted, the replication dataset(s) are not provided on the OSF. Rather, you will need to follow
the instructions and code to first reconstruct the datasets, and then proceed with your work. In such
cases, the team responsible for creating the dataset(s) has provided summary statistics in the OSF that
correspond to the constructed datasets, so you can verify that the datasets you create match what they
intended.
You’ll be responsible for filling out sections 16-25 of the preregistration below. Before you do so, please
review the original study, sections 1-15 of the preregistration, and the materials provided on the
OSF, so that you are familiar with all of the decisions that have been made to date. In many cases, the
‘data preparer’ will have left you instructions and suggestions on how the provided data can be used in
the analysis, as well as idiosyncrasies and discrepancies in the data that you should be aware of. The
data preparers have tried to be thorough in including all variables that you might need, but please keep in
mind the following:
●
Some of the variables included in the constructed dataset(s) may not be needed in the final
analysis, so please do not feel the need to necessarily use all of the provided variables.
●
Some of the variables needed might have mistakenly been excluded from the constructed
datasets. If you find that this is the case, please let Andrew or Anna know, and they will work with
you to supplement the datasets as needed.
For these secondary data replications, we would like the analysis plan to be completed before the
preregistration goes through review, so that after review, the only remaining steps are registration and
running the analysis code on the full datasets. To facilitate that, we are asking that you include in section
19 a link to the code you will use that takes the constructed dataset(s) provided to you and produces the
focal analysis (including all of the cleaning, merging, and transforming required). When developing your
analysis plan and code, please randomly sample 5% of the data for use in your work and demonstrate
that the focal analysis produces sensible results using just that random sample by providing a screenshot
of the output (see section 19 for details). Do not use the rest of the data until after your study is
registered and it is time to run the final analysis. In section 19, you will find a statement that we are
asking you to bold that confirms you’ve only used 5% of the data when developing and testing your code.
If this approach will not work for any reason, please let Andrew or Anna know and disclose deviations
from this plan somewhere in the preregistration.
●
In cases where we are providing you a complete dataset, you can just sample out 5% of the
observations and hold the rest out until you are ready to perform the final analysis.
●
In cases where we are providing you multiple datasets that need to be combined prior to analysis,
please sample out 5% of the observations in whatever way is most sensible.

○
For example, in cases where each dataset contains complete observations on its own (a
typical 'row bind' situation), it makes the most sense to sample out 5% of each dataset
separately and then combine them together to develop and test your code.
○
In cases where datasets need to be merged in order to create complete observations (a
typical 'column bind' situation), it makes the most sense to merge the separate datasets
into a full dataset first, and then sample out the 5% before proceeding with the rest of the
analysis code.
●
We leave the decision on how to sample out the random subset of data to you, so long as (a) you
are not performing any analyses on the complete dataset until after your study is registered and
(b) whatever decision you make is documented in the preregistration.
Finally, in cases where the replication data combines observations from the original study with
observations that were not used in the original study (what we are calling ‘hybrid replications’), please
perform up to three analyses (details immediately below). This will likely require you to subset your data,
based on the description of the original analysis provided in the study.
●
When the ‘new’ data alone can clear the minimum power threshold, please perform one analysis
that relies only on the ‘new data’ (the focal analysis), one analysis that relies on all available data,
and a third analysis that relies only on the original data. Please make sure all three analyses are
documented (with code) in section 19 below.
●
When the ‘new’ data alone cannot clear the minimum power threshold, please perform one
analysis that combines all available data, and a second that only uses the old data. Please make
sure both analyses are documented (with code) in section 19 below.
Please contact Andrew or Anna if you have any questions. After you’ve completed the remaining
sections of the preregistration and uploaded all the necessary materials to the OSF, please
contact the SCORE coordinators regarding next steps.

Preregistration of Andrews_BritJournPoliSci_2009_Ryq7
Existing Data Replication
Study Information
1. Title (provided by SCORE)
RR TEAM INSTRUCTIONS: This has been determined by SCORE.
Replication of a research claim from Andrews & Money (2009) in British Journal of Political
Science.
2. Authors and affiliations
RR TEAM INSTRUCTIONS: Fill in the names and affiliations of your team below.
Marco Ramljak A1
Esteban Méndez-Chacón2
1 Utrecht University
2 Central Bank of Costa Rica
3. Description of study (provided by SCORE)
RR TEAM INSTRUCTIONS: This description has been provided by SCORE. Please review and
make a SCORE project coordinator aware of any edits, additions, and corrections you would
suggest to the paragraph. You are free to add additional descriptions of your project in a
separate paragraph.
The claim selected for replication from Andrews & Money (2009) is that, as the number of
parties in the system increases so too does the dispersion of parties, but only up to a point. The
boundaries of a finite policy space appear to expand up to five parties; the positive relationship
between the number of parties and the dispersion of parties is the portion of this finding selected
for the SCORE program. This reflects the following statement from the paper's abstract: "They
found that as the number of parties in the system increases, the dispersion of parties also
increases, but only up to a point." The claim is tested with regression analysis, where the
dependent variable is dispersion. To measure party dispersion, the authors calculate the
distance between the policy positions of the two most extreme parties in the party system along
both the economic and social policy dimensions, which results in a measure of dispersion for
economic and social policy; for the analysis selected for the SCORE program (Model 1a, Table

4), the measure for economic policy is used. For data on the policy positions of parties the
authors employ the Comparative Manifesto Project (CMP). The explanatory variable of interest
is the number of parties in the party system. The authors take the natural log of both the
dispersion variable and the number of parties variable (see Model 1a for specification details of
the full model). The authors find that as the number of parties in the system increases, party
dispersion increases and the effect is statistically significant for both policy dimensions
(economic policy dimension is selected for the SCORE program) (coefficient on log count of
parties in system term = 0.39, robust SE clustered by country = 0.14, coefficient falls within a
95% confidence interval).
4. Hypotheses (provided by SCORE with possible Data Analyst additions)
RR TEAM INSTRUCTIONS: The focal test for SCORE is indicated as H*. If you will test
additional hypotheses (or use alternate analyses) that help you to evaluate the claim your
replication/reproduction is testing, number them H1, H2, H3 etc. (You can place H* in the list
wherever makes sense). Please make sure that any additional hypotheses are logical
deductions/operationalizations of the selected SCORE claim or are necessary to properly
interpret the focal H* hypothesis.  Research that is outside this scope should be described in a
separate preregistration.
Specific points to keep in mind (please also consult the Reviewer Criteria):
●
Are the listed hypotheses specific, concise, clearly testable, and specified at the level of
operationalized variables?
●
Are hypotheses identified as directional or non-directional, and, if applicable, have the
direction of hypotheses been stated? (Example: “Customers’ mean choice satisfaction
will be higher in the CvSS architecture condition than in the standard attribute-by-
attribute architecture condition.”)
●
Does the list of hypotheses/tests indicate whether additional hypotheses are taken from
the original study or modified/added by the team?
H*: On the economic policy dimension, the number of parties in the party system is positively
associated with policy dispersion.

Design Plan
5. Study type
NOTE: The study type selected should be based on the data collected for the replication, and
not necessarily the data used in the original study.
●
Experiment - A researcher randomly assigns treatments to study subjects, this includes
field or lab experiments. This is also known as an intervention experiment and includes
randomized controlled trials.
●
Observational Study - Data is collected from study subjects that are not randomly
assigned to a treatment. This includes surveys, natural experiments, and
regression discontinuity designs.
●
Meta-Analysis - A systematic review of published studies.
●
Other
6. Blinding
RR TEAM INSTRUCTIONS: Select any/all of the below that apply for your study by bolding
them. You will give a longer description in the next question.
●
No blinding is involved in this study.
●
For studies that involve human subjects, they will not know the treatment group to which
they have been assigned.
●
Personnel who interact directly with the study subjects (either human or non-human
subjects) will not be aware of the assigned treatments. (Commonly known as “double
blind”)
●
Personnel who analyze the data collected from the study are not aware of the treatment
applied to any given group.
[QUESTION 6 - BOLD YOUR RESPONSE ABOVE]
7. Blinding
RR TEAM INSTRUCTIONS: Since all existing data replications are based on data that has
already been collected, in most cases it will not be necessary to comment on participant
blinding. In the rare instance when an existing experiment is being re-analyzed for an existing
data replication and blinding is a relevant consideration, please provide below any details
regarding blinding that are important for a reviewer to be aware of.
No blinding was involved to the secondary data collectors’ knowledge.

8. Study Design
RR TEAM INSTRUCTIONS: Please describe how data was collected in the original study and
how it compares to the data that was selected for the replication attempt. Explain why the data
selected for the replication study is suitable for a replication and if any substantial deviations
exist between the two.
If the data used in the replication combines observations from the original study with new
observations (e.g. if the data selected for the replication attempt comes from the same
longitudinal survey as the original study), describe how ‘original’ and ‘new’ observations relate to
each other and an estimate for what proportion of the final dataset’s observations will be
comprised of original vs. new observations.
Specific points to keep in mind (please also consult the Reviewer Criteria):
●
Does the preregistration specify the unit of analysis?
●
Does the preregistration provide sufficient detail about how the data selected for the
replication attempt deviates from or is congruent with the data employed in the original
study?
●
Does the preregistration describe whether and how ‘original’ and ‘new observations’ are
combined together for the replication dataset?
Concerning the main SCORE claim, the original study scrutinizes the effect of the number of
political parties in an election on the overall party position dispersion on economic policy. The
authors conduct their study on 20 countries, including all national elections (n = 275) in the time
frame 1945-1999. For this, the authors utilize political party position data from the Comparative
Manifesto Project (CMP) (left-right scale on economic policy) and administrative electoral data
such as, number of parties involved in the particular election and the type of electoral system
(single member district systems vs.proportional systems). Therefore, five variables can be
established: one dependent variable, measuring the dispersion of the respective election
concerning economic policy, indicated by the range of the left-right scale between the two most
extreme parties. One main independent variable, measuring the number of parties involved, and
three (control/supportive) variables, (1) classifying the type of electoral system, (2) past party
dispersion (lagged dependent variable) and the (3) country cluster (multilevel variable). The
unique identifier of the dataset are the respective elections (n = 275). These variables are
searched for, for a potential replication dataset.
As the focal claim of the original study focuses on 275 elections of 20 established modern
parliamentary democracies in the time frame 1945-1999, I propose to widen the replication
dataset - both in countries and in time. Therefore, the main data source will be the CMP (same
data source of the original study) and for the administrative data (not indicated how or from
where it was collected in the original study) I will use the Comparative Political Data Set

(CPDS). The variables and the operationalizations of the CMP have not changed over the time
in any relevant way, therefore they can be used without any changes necessary.
While collecting the administrative electoral data is straightforward because it cannot vary
between data sources, there might be varying information between suitable sources on party
positioning data. A suitable supportive pendant to the CMP data is the Chapel Hill Expert
Survey (CHES), which surveys Political Science experts in the individual countries to rate
parties on their left-right scale for economic and social policy, among other topics. Next to the
main data source, the CMP, the CHES could increase robustness of the analysis. That being
said, the main source for the dependent variable in the proposed replication dataset is the
ongoing data from the CMP. Appropriate information from the CHES for further robustness
control will be included in the data delivery.
The original study includes the following countries: Australia, Austria, Belgium, Canada,
Denmark, France, Germany, Greece, Iceland, Ireland, Italy, Luxembourg, Netherlands, Norway,
New Zealand, Portugal, Spain, Sweden, Switzerland and the United Kingdom. The authors
relate their research to modern established parliamentary democracies (p. 805) and use existing
administrative electoral data. The paper does not further specify, to what electoral/governmental
systems (other countries) the findings apply, therefore further “modern, established
parliamentary systems” should be considered into a potential replication dataset. This logic also
applies to a more recent timeframe, as there is - in my opinion - no applicable argument
mentioned, why the findings should not relate to more recent elections. Therefore, for the
replication dataset, I propose to use the original dataset from 1945-1999, add more recent data
of the already existing countries (2000-2019) and add the following 9 countries which are either
EU and/or OECD countries (available data from CMP and CPDS): Bulgaria, Croatia, Czech
Republic, Estonia, Finland, Hungary, Latvia, Poland, Slovakia.
9. Randomization (free response)
RR TEAM INSTRUCTIONS: If the variables used for this replication attempt were randomized,
state how they were randomized, and at what level.
No variables for this study have been randomly assigned.
Sampling Plan
This section describes how the data sources for the replication were selected, how they were
prepared into a replication dataset, and the number of observations that will be analyzed from
these data. Please keep in mind that the data described in this section are the actual data used

for analysis, so if you are using a subset of a larger dataset, please describe the subset that will
actually be used in your study.
10. Existing data (multiple choice question, provided by SCORE)
1.1.1.
Registration prior to creation of data
1.1.2.
Registration prior to any human observation of the data
1.1.3.
Registration prior to accessing the data
1.1.4.
Registration prior to analysis of the data
1.1.5.
Registration following analysis of the data
11. Explanation of existing data
NOTE: For replications that rely on existing data sources, this question refers to the data that
will be used for the replication analysis (i.e. the final replication dataset), and not (a) the data
from the original study or (b) the data sources accessed to construct the replication dataset.
Since no new data will be created for ‘existing data replications,’ 1.1.1 should never be selected.
Since all analyses will occur after registration, 1.1.5 should also never be selected.
The final datasets needed for replication (CMP, CPDS and CHES) have been accessed, and
cleaned to a very low degree prior to registration. All originally used years and available
subsequent years of the original data sources (reference point: the years used in the original
dataset) were chosen because the necessary variables were available in all of them. Therefore,
the replication dataset will be a combination of the originally used observations and new
observations - these will be marked with a separate helper variable. Most of the selected
variables in the final datasets are the same ones that were used in the original study. None of
the variables nor observations were selected because of their likelihood (or not) of leading to a
confirmatory result.
12. Data collection procedures
RR TEAM INSTRUCTIONS: Please describe the process for constructing the replication
dataset in as much detail as you can. The sections below should be used to provide the
following information:
●
Which variables are needed from the original study to perform a good-faith, high-quality
replication.
●
Which data sources were used, why they were selected, any deviations between the
original study design and the replication study design that these selections present, and
the procedures used to access the data.
●
Which of the variables from the original study are available in the replication data
sources, including relevant details about each measure.
●
The procedure for creating the replication dataset, in both narrative and script form.
●
A data dictionary that documents each variable included in the replication dataset.

In the sections below, please provide links to the original materials whenever possible --
including descriptions of the original datasets and corresponding codebooks. If materials can be
shared on the OSF, please do so, and provide view-only links to those materials.
Specific points to keep in mind for reviewers:
●
Does the preregistration describe which data sources were selected for the replication
study and why each is suitable?
●
Does the preregistration make clear how the data sources were used to construct the
replication dataset?
(a) Data Needed
RR TEAM INSTRUCTIONS: List below the datasets and variables the original author used to
analyze the focal claim. Include details regarding the sample size, waves or years used, and
other details pertinent to finding an existing dataset for replication. Please include page
numbers when excerpting from the original article. If possible, categorize the list of variables as
one of the following: dependent variable, focal independent variable, control variable, or sample
parameters/clustering variable. Finally, include the sample size of the original study’s focal
analysis, if it is available.
As described above, the unit of observations in the focal analysis is elections (n = 275, from 20
countries, in 1945-1999) and the following variables are needed for the replication of the focal
claim:
Dependent variable:
●
Dispersion concerning economic policy of the current political arena (election)
○
Source: CMP
○
Further operationalization for regression analysis:
■
Units are defined by principal component analysis (Correlation: 0.96)1
■
Countries are pooled to create the measure “of party dispersion based on
a common policy space and a common metric” p. 812)
■
natural log because of skewness
○
Needed variables in CMP for construction of index (p. 814):
■
303 (government and administrative efficiency),
■
401 (free enterprise),
■
402 (incentives),
■
403 (market regulation),
■
404 (economic planning),
■
407 (protectionism, negative),
■
412 (controlled economy),
■
413 (nationalization),
1 I expect similar values for the subsequent years.

■
414 (economic orthodoxy),
■
504 (welfare state expansion),
■
505 (welfare state limitation),
■
701 (labor groups, positive)
Independent variable:
●
Number of parties involved
○
Source: CMP
○
Unit: party count, 2-13
○
Further operationalization:
■
Every party is counted for each election with at least 1 percent of gained
seats in at least two consecutive elections (p.810).
■
Drop if a party fails to gain 1 per cent of the seats in three subsequent
(and consecutive) elections (p. 810).
■
The measure of party dispersion includes only parties which are included
in the particular election (p.816).
■
Natural log because of skewness
○
Needed variables in CMP:
■
Absolute number of gained seats by the party (absseat)
■
Total number of seats to be gained in respective election (totseats)
Control variables:
●
Type of electoral system
○
Source: probably desk research, not further indicated
○
Units: Single member district vs. proportional system
○
Further operationalization for regression analysis:
■
Dummy transformation
●
Past party dispersion in the country
○
Lagged version of dependent variable (p. 821)
●
Country cluster variable (p.821)
○
Which country does the election resonate from
○
Appropriately tackling “within country” effects by applying multilevel model
structure
Further note:
●
Even though the paper stresses that it constructs a bidimensional policy space, the
regression analysis of the focal claim operationalizes the dependent variable only based
on the economic policy dimension, excluding the social policy dimension. The social
policy dimension is modeled in an extra model, which is not part of the SCORE focal
claim.

(b) Data Access
RR TEAM INSTRUCTIONS: Describe below the data sources that will provide the replication
variables. Include information such as the name of the data source (e.g., Indonesian Family Life
Survey), the description and link of the data source, and the waves needed to create a final
replication dataset.
Also describe the process for accessing the data sources that will be used to create the final
replication dataset; specify how long long it took for the registration to be approved and what
information was required (e.g., writeup of the purpose of the project, email address from an
IPCSR institution, etc.); and verify that the data can be opened as expected. If applicable,
provide a link to the page where you registered to access the data.
Describe in detail any restrictions on data access and data-sharing, as well as any additional
terms of data use that will be relevant for the replication study and final report (e.g. citations that
will need to be made). If you were able to access the data because of special permissions that
you have, but that you expect other researchers might not have, please document those as well.
Main Data source: Manifesto Project (CMP)
The data source for replication is the same as in the original study (CMP), however more recent
years (2000-2019) will be added to the original sample and more countries (indicated above).
These additions can be made due to more recent data in the CMP data set.
●
Data source (version 2019b): https://manifestoproject.wzb.eu/datasets
●
Codebook:
https://manifestoproject.wzb.eu/down/data/2019b/codebooks/codebook_MPDataset_MP
DS2019b.pdf
The CMP is freely available for research purposes and offers a very user-friendly platform. A
free registration is needed to download the data in a machine-readable format (Stata, SPSS,
.csv and Excel are available). The registration process including activation and approval of the
account is done within minutes. Usual individual information is asked e.g. name, address,
institution, which can be filled in however only a valid email address and a password are
necessary to complete registration. The complete data file with codebook can be downloaded (3
mb unzipped). The data file and the codebook can be successfully opened. (register link:
https://manifesto-project.wzb.eu/signup)

Analyses done with the CMP can be done freely for any kind of institution and research. It
cannot be shared without prior permission. For citations in academic journals the following
should be used:
“Volkens, Andrea / Krause, Werner / Lehmann, Pola / Matthieß, Theres / Merz, Nicolas / Regel,
Sven / Weßels, Bernhard (2019): The Manifesto Data Collection. Manifesto Project
(MRG/CMP/MARPOR). Version 2019b. Berlin: Wissenschaftszentrum Berlin für Sozialforschung
(WZB). https://doi.org/10.25522/manifesto.mpds.2019b“
Further data source: Comparative Political Data Set (CPDS)
For valid information on one of the control variables “Type of electoral system” I propose to use
the CPDS dataset as it delivers in its most recent version the necessary information for all
countries and respective years posed (1960-2017).
Data source:https://www.cpds-data.org/index.php/data#CPDS
Codebook:
https://www.cpds-data.org/images/Update2019/Codebook-CPDS-1960-2017-Update-2019.pdf
The CPDS is a reliable data source for election relevant data. It is freely available for research
purposes and does not require any registration.
Analyses done with the CPDS can be done freely for any kind of institution and research. For
citations in academic journals the following should be used:
“Armingeon, Klaus, Virginia Wenger, Fiona Wiedemeier, Christian Isler, Laura Knöpfel, David
Weisstanner and Sarah Engler. 2019.
Comparative Political Data Set 1960-2017.
Zurich: Institute of Political Science, University of Zurich.”
Further data source: Chapel Hill Expert Survey (CHES)
In order to increase robustness of the potentially replicated findings I propose to add available -
differently collected information - on the dependent variable “Dispersion concerning economic
policy of the current political arena”. Further info on the proposed operationalization will be
presented below.
Dataset:  https://www.chesdata.eu/ches-europe
Codebook:
https://static1.squarespace.com/static/5975c9bfdb29d6a05c65209b/t/599d0c06bebafbcd8c66ed
fa/1503464455314/1999-2014_CHES_codebook.pdf
The CHES is a reliable data source for election relevant data. It is freely available for research
purposes and does not require any registration. Analyses done with the CHES can be done

freely for any kind of institution and research. For citations in academic journals the following
should be used:
“Polk, Jonathan, Jan Rovny, Ryan Bakker, Erica Edwards, Liesbet Hooghe, Seth Jolly, Jelle
Koedam, Filip Kostelka, Gary Marks, Gijs Schumacher, Marco Steenbergen, Milada Anna
Vachudova and Marko Zilovic. 2017. "Explaining the salience of anti-elitism and reducing
political corruption for political parties in Europe with the 2014 Chapel Hill Expert Survey data,"
Research & Politics (January-March): 1-9.”
and,
“Ryan Bakker, Catherine de Vries, Erica Edwards, Liesbet Hooghe, Seth Jolly, Gary Marks,
Jonathan Polk, Jan Rovny, Marco Steenbergen, and Milada Anna Vachudova. 2015."Measuring
party positions in Europe: The Chapel Hill expert survey trend file, 1999-2010." Party Politics
21.1: 143-152.”
(c) Variable Availability
RR TEAM INSTRUCTIONS: For each variable required for the replication analysis (listed
above), describe the variables from the replication data that can be used to measure it
(including which data files or sources each measure is found in), any notes a data analyst
should consider when using the measure in a replication analysis, and any important
differences between the original variable and the proposed replication variable.
If there are multiple variables in the replication data that correspond to a required variable (e.g.
two different measures of education in the replication data), include all of those options below. If
a variable from the original study cannot be measured using the replication data, please make
that clear as well. Finally, include a description of the identifiers used to merge multiple
datasets, if applicable.
Dependent variable:
●
Dispersion concerning economic policy of the current political arena (election)
○
Source: CMP
○
Further operationalization for data analyst:
■
Units needs to be defined by principal component analysis
■
Countries need to be pooled to create the measure “of party dispersion
based on a common policy space and a common metric” p. 812)
■
Take the natural log because of skewness
○
Needed variables in CMP for construction of index (p.814):
■
303 (government and administrative efficiency),
■
401 (free enterprise),
■
402 (incentives),
■
403 (market regulation),
■
404 (economic planning),
■
407 (protectionism, negative),

■
412 (controlled economy),
■
413 (nationalization),
■
414 (economic orthodoxy),
■
504 (welfare state expansion),
■
505 (welfare state limitation),
■
701 (labor groups, positive)
Independent variable:
●
Number of parties involved
○
Source: CMP
○
Unit: party count
○
Further operationalization for data analyst:
■
Every party is counted for each election with at least 1 percent of gained
seats in at least two consecutive elections (p.810).
■
The measure of party dispersion should only include parties which are
included in the particular election (p.816).
■
Take the natural log because of skewness
○
Needed variables in CMP:
■
Absolute number of gained seats by the party (absseat)
■
Total number of seats to be gained in respective election (totseats)
Control variables:
●
Type of electoral system
○
Source: CPDS (1960-2017)
○
Units: 0 = single-member, simple plurality systems; 1 = modified proportional
representation (parallel plurality PR-systems, majority-plurality/alternative vote); 2
= proportional representation (PR).
○
Further note: Missing values for elections before 1960 and after 2017 were
imputed with the most suitable value in the CPDS (valid value closest in year).
This is possible because the “type of electoral system” is a very stable variable
within a country. It should also be noted that this variable is not significant in the
focal analysis and the authors stress that this cannot be a “country-within”
explanatory variable as there is barely variation (p.813)
○
Further operationalization for data analyst:
■
Dummy transformation: a variable equal to 1 if the country has a single
member district electoral system, and 0 otherwise.
●
Past party dispersion in the country
○
Further operationalization for data analyst:
■
Lagged version of dependent variable (p. 821)
●
Country cluster variable (p.821)
○
Units: 29 countries
○
Further operationalization for data analyst:

■
Multilevel operationalization
Identifiers:
The two delivered datasets resonating from the CMP and the CPDS respectively are on the
following levels:
●
CMP: Country-election/election year-party
●
CPDS: Country-election/election year
These identifier levels are found in the respective data files. They still differ in levels as the data
analyst needs to derive the dependent and the independent variable before summarising the
dataset on the Country-election/election year level, when it can be merged with the CPDS for
the final analysis level.
Bonus variable: (Optional)
●
Dispersion concerning economic policy of the current political arena (election)
○
Source: CHES
○
Further note: This is an equivalent variable for the above introduced dependent
variable but from a different source with a different methodology. It is only
available for a small proportion of the available observations. It can be used
optionally by the data analyst for further robustness control.
○
Units: numeric position of the party in the respective election in terms of its
ideological stance on economic issues (0 = extreme left,..., 5 = center, …, 10 =
extreme right)
○
Further operationalization for data analyst:
■
Observations in the dataset are on the same level as the CMP
■
CHES data entails a CMP party identifier which can be used for merging
with CMP for every election.
(d) Data Creation
RR TEAM INSTRUCTIONS: Create a dataset using the data sources and variables listed
above. Provide a detailed narrative describing how the various datasets were cleaned and
merged into a final replication dataset. Provide a view-only link to a clearly commented script on
the OSF that produces the replication data as described in the narrative. Our preference is that
this be either an R script or a script from another language that similarly allows for open and
reproducible analyses. Please let the SCORE team know if this is not possible.
●
If the data can be freely shared and posted to OSF, please post it in your OSF project
and provide a link to the completed dataset below.
●
If any part of the dataset cannot be shared between researchers or posted to the OSF,
please leave the final dataset off the OSF. Instead, include either below or in your script
(commented out at the bottom) two pieces of information that will help an independent
team verify they have created the dataset according to your instructions:
○
The dimensions of the final dataset(s) you’ve created (# of rows, # of columns)

○
A summary of 8-10 variables in the replication dataset. For numeric variables, the
summary should include the mean, standard deviation, and count of NAs. For
categorical variables, the summary should include each level present in the data
and its count, as well as a count of NAs. If multiple datasets are submitted as part
of your work, at least one variable should be included from each dataset.
The data from the replication sources should be preserved in as ‘raw’ a form as possible, in
order to give the data analyst the most latitude to clean the variables as they see fit. Variables
from the original source should be preserved in their original form (e.g. do not recode values of
99 to NA). New variables should only be created when they’re needed to complete the merge or
combine the datasets; in those cases, please preserve a version of the original, unaltered
variable in the new dataset.
When combining multiple datasets by binding rows, please be sure that the data type and
measurement units are equivalent across each dataset. If there is a discrepancy in how a
variable is measured across datasets, rename the variable in each dataset to indicate the
original dataset, and then carefully document the resulting measures below and in the data
dictionary. See here for an example of how this should work.
Please also use this section to describe:
●
Any deviations between the original study design and the replication design that would
result from using this replication dataset.
●
Any notes about using these variables that you would like to pass along to the data
analyst.
Datasets, code and resources:
In total there are three cleaned datasets (CMP, CPDS and CHES) of which two are uploaded to
the OSF project (CPDS.final and CHES.final) . Data derived from the CMP is not allowed to be
2
shared:
There is one script for the cleaning of all three datasets which can be found in “ANDREWS
code.r”.
The relevant codebooks can be found here: CMP codebook, CPDS codebook, CHES codebook
A variable is created by the data finder (data.sample) to differentiate between observations in
the original study and new proposed observations as the proposed replication is a combination
of both. This is further described in section 13.
2 I have uploaded the raw files as well: CPDS.raw and CHES.raw

Furthermore, CPDS.final holds data now from 1945-2019 because the variable “type of electoral
systems” was imputed for elections from old countries between 1945-1960 as well as for
elections after 2017. Elections from new countries only have imputed values for elections after
2017 because possible elections prior to 1999 are not included in the proposed replication
dataset. A variable was created to differentiate values which were imputed from unimputed
ones. The imputation logic is explained in 12c.
Further notes for the data analyst:
●
Please download the raw CMP dataset according to the instructions indicated in 12b.
●
Run the code for this dataset to create the object CMP.final.
●
The dependent and independent variables in the CMP.final object need to be created, as
indicated in the 12c.
○
To build the dependent variable a Principal Component analysis is necessary. It
might be helpful to check the official codebook of the CMP codebook (p.9
onwards) for this.
●
(Optionally, the Bonus variable as indicated in 12c can be created with the CHES.final
object. This can then be merged with the CMP.final object.)
●
After this the CMP.final object can be summarised on the country-election/election year
level.
●
CMP.final can now be joined with CPDS.final to retrieve the control variable “type of
electoral systems”.
●
After this, the final object should be analysis ready for the SCORE focal claim model.
Summary statistics of CMP.final object for data verification purposes:
●
Summary values for totseats:
○
Min: 26; Max: 709; Mean: 257.8; SD: 166.3338
●
Summary values for per403:
○
Min: 0; Max: 25; Mean (without NAs): 2.186; SD (without the 9 NAs): 2.638678
●
Summary values for per504:
○
Min: 0; Max: 65.854; Mean (without NAs): 2.186; SD (without the 9 NAs):
6.026836
(e) Data Dictionary
RR TEAM INSTRUCTIONS: Create a data dictionary following this template. Provide below a
view-only link to the completed data dictionary included in the OSF project. If the Data Analyst
will need to create new variables using the variables in the final replication dataset (e.g.
recoding the provided education variable to be in a better format for analysis), please document
below your recommendation on how the analyst should do so. Please also document any
additional notes regarding the variables in the dataset that do not fit within the provided data
dictionary template or the other sections above.

The data dictionary can be found here.
13. Sample size
RR TEAM INSTRUCTIONS: Please report below the analytic sample size(s) in the replication
dataset, with reference to however many units or levels are in the data. Please report as much
information here as will be helpful for the review committee to be aware of, including differences
in sample size resulting from various analytic decisions (e.g. listwise deletion vs multiple
imputation). Finally, when the replication combines observations from the original study
with new observations, please estimate what proportion of the analytic sample’s
observations will be comprised of original vs. new observations.
Data finders’ response goes here:
The original study uses available elections from 20 countries in the time frame 1945-1999 with a
final observation count of 275. The proposed replication dataset is a combination of the original,
recreated sample and both, new observations of the already included countries (20 countries,
2000-2019), and new observations from 9 further EU and/or OECD member countries (9
countries, 2000-2019). In total, the proposed replication dataset will therefore contain
observations from 29 unique countries and elections in the time frame between 1945-2019. As
the delivered datasets are not yet on the final country-election/election year level (needs to be
done by the data analyst), the following sample size will only be an estimation. The data finder
counted the unique elections per country in the raw CMP data file for the 4 types of
observations (elections from old countries and old timeframe; elections from old countries and
new time frame; elections from new countries and new time frame):
●
Elections from old countries and old timeframe: 304
●
Elections from old countries and new time frame: 107
●
Elections from new countries and new time frame: 44
In total there would be 455 available elections in the proposed replication dataset. However, one
should notice that there are 29 extra elections in the old sample (n = 275 in original study),
which apparently were not valid for the original study - this is probably due to missingness and
represents about 10% of the available 304 elections. This missingness proportion will be
considered for the final sample size estimation. Therefore, one can add about 136 new
observations to the original sample of 275 observations which leads to a sophisticated
guess of about 411 unique elections in the analysis ready replication sample.
------
Required sample size [to be filled out by the SCORE team]: The primary unit of analysis is the
country. An estimate of the minimum viable sample size for the data analytic replication is: 12.

For comparison, the stage1 required sample size would be: 51 and the stage2 sample size
would be: 111.
Notes: The SER method assumes the structure of the data (in terms of observations per
country) is the same across original and replication, with the sample size changes being mainly
done through changing in the number of countries because that will have a larger effect on the
power than changing the number of observations within a country in this study.
14. Sample size rationale
For data analytic replications in SCORE, three sample sizes are calculated:
●
A minimum threshold sample size, defined as the sample size required for 50% power of
100% of the original effect
●
A stage 1 sample size, defined as the sample size needed to have 90% power to detect
75% of the original effect
●
A stage 2 sample size, defined as the sample size needed to have 90% power to detect
50% of the original effect
Details about how those sample sizes were calculated for this project are found here.
15. Stopping rule (provided by SCORE)
RR TEAM INSTRUCTIONS: For replications and reproductions involving existing data, this
section describes which analyses the SCORE team is recommending be performed. Most often,
this corresponds to analyses involving new data, original data, or a combination of new and old
data.
Because the replication data combines observations used in the original analysis with a new set
of observations, SCORE recommends performing two analyses:
●
One analysis that uses all available observations. This will be the focal analysis of the
replication study.
●
A second analysis that only uses observations that were used in the original analysis.
This will be the focal reproduction analysis of the study.
Variables
RR TEAM INSTRUCTIONS: The preregistration form divides variables across three questions:
manipulated variables, measured variables, and indices (i.e. analytic variables derived from raw
variables). For existing data replications, only fill out the “Measured variables’ and ‘Indices’
sections. Please do not fill out anything in the ‘Manipulated variables’ section.

The raw data of any transformed variable (e.g. reaction time → log reaction time) or any created
index should be defined in the ‘Measured variables’ section. Details regarding the variable
transformation should be specified in the ‘Transformations’ section. Details regarding the
creation of an index should be specified in the ‘Indices’ section.
Across these questions, you should define all variables that will later be used during your
analysis (including data preparation/processing). You can describe all variables in the
preregistration and/or summarize and link to a data dictionary (codebook) in your repository to
answer these questions.
If you will share data from your replication, this is also the place to state whether any variables
will be removed prior to sharing the dataset (e.g. to reduce risk of participant identification or
comply with copyright restrictions on scale items.)
16. Manipulated variables
RR TEAM INSTRUCTIONS: Manipulated variables in this preregistration refer specifically to
variables that have been randomly assigned in an experiment. The use of data from an
experiment should be rare in existing data replications. If your existing data replication relies on
experimental data, please document each manipulated variable as a measured variable, and
use the codebook to indicate what each level of the variable corresponds to (e.g. participants
assigned to the treatment condition = 1; participants assigned to the control condition = 0). The
default language in bold below has been copied into all existing data replication preregistrations.
N/A -- not documented for existing data replications.
17. Measured variables
RR TEAM INSTRUCTIONS: Please use this section to document each variable that was used
in the original study’s analysis and the role it served (e.g. dependent variable, control variable,
sample parameter, etc). For each variable, provide the description of the variable offered in the
paper and/or codebook of the original study, the variable in the replication dataset that it
corresponds to, and explain any deviations between the two. In cases where an equivalent
replication variable was not found, explain how, if at all, you expect it will affect the replication
attempt. In cases where you are adding a variable that was not present in the original study,
please explicitly state that you are doing so, and explain how, if at all, you expect it will affect the
replication attempt.
Specific points to keep in mind (please also consult the Reviewer Criteria):
●
Does the preregistration surface all of the variables needed to replicate the focal
analysis?

●
Are deviations between the original variables and replication variables documented
when needed?
Note: For the replication, lines 50 to 151 of the Stata do-file
“Andrews-Money_Replication_5_Random_Sample.do” generate the variables described below.
For the reproduction, the corresponding lines are 51 to 152 of the Stata do-file
“Andrews-Money_Reproduction_5_Random_Sample.do.”
DISPERSION
●
Use in the analysis: Dependent variable.
●
Description from the original study: “Our numerical estimates of party positions along
each of our two dimensions correspond to the scores of the first component of a principal
components analysis on each set of coding categories for the twenty countries included
in our study. The end result of our analysis is an estimated policy position on the
economic and social dimensions for each party in each election year from 1945 to 1999.”
(page 814)
“The original Comparative Manifesto Project coding categories that are included in our
economic policy dimension are: 303 (government and administrative efficiency), 401
(free enterprise), 402 (incentives), 403 (market regulation), 404 (economic planning),
407 (protectionism, negative), 412 (controlled economy), 413 (nationalization), 414
(economic orthodoxy), 504 (welfare state expansion), 505 (welfare state limitation), 701
(labor groups, positive).” (page 814)
“To measure party dispersion, we calculate the distance between the policy positions of
the two most extreme parties in the party system along both the economic and social
policy dimensions, which results in a measure of dispersion for economic and social
policy. We record dispersion for each party system depicted in Figure 1. The units of
dispersion are determined by the principal components analysis and are comparable
across party systems.” (page 815-816)
“Our two variables of interest – dispersion and number of parties in the party system –
are both skewed. Therefore, we take the natural log of each variable and use these
transformed variables in our regression analysis.” (page 821)”
●
Variables used in the replication: First, using the same parties as in the count of parties
in the system variable, a principal component analysis is implemented, using the
variables:
○
per303 (government and administrative efficiency)
○
per401 (free enterprise)
○
per402 (incentives)
○
per403 (market regulation)
○
per404 (economic planning)
○
per407 (protectionism, negative)
○
per412 (controlled economy)
○
per413 (nationalization)
○
per414 (economic orthodoxy)

○
per504 (welfare state expansion)
○
per505 (welfare state limitation)
○
per701 (labor groups, positive)
Then, for each party used it is obtained the predicted principal component (factor) score
for the first component. Finally, for each election, the distance between the most extreme
parties is obtained.
●
DISPERSION corresponds to the distance between extreme parties along the economic
dimension. Note that the OLS regression uses the natural log of DISPERSION.
●
No deviations between the original study and the replication/reproduction study.
COUNT_PARTIES
●
Use in the analysis: Focal independent variable.
●
Description from the original study: “To be included in our measure, a party must have
gained at least 1 per cent of the seats in parliament in at least two consecutive elections.
If a party fails to gain 1 per cent of the seats in three subsequent (and consecutive)
elections, we drop it from our measure. According to this criterion, the number of parties
in a party system is assessed on an election by election basis, and it can, in theory,
change with each election.” (page 810)
“Our two variables of interest – dispersion and number of parties in the party system –
are both skewed. Therefore, we take the natural log of each variable and use these
transformed variables in our regression analysis.” (page 821)”
●
Variables used in the replication:
○
Absolute number of gained seats by the party (absseat)
○
Total number of seats to be gained in respective election (totseats)
●
COUNT_PARTIES corresponds to the count of parties in the system. Note that the OLS
regression uses the natural log of COUNT_PARTIES.
●
No deviations between the original study and the replication/reproduction study.
SINGLE_MEMBER
●
Use in the analysis: Control variable.
●
Description from the original study: “In Models 1 (a & b) and 2 (a & b), we evaluate the
effect of number of parties in the system, as measured by count of parties and by
effective number of parties, and electoral rules, as measured by a dummy variable
coded 1 if the country has a single member district electoral system, on dispersion.”
(page 821)
●
Variables used in the replication:
○
Electoral system: single member districts or proportional representation (prop)
○
Total number of seats to be gained in respective election (totseats)
●
SINGLE_MEMBER corresponds to a dummy variable equal to 1 if the country has a
single member district electoral system, and 0 otherwise.
●
No deviations between the original study and the replication/reproduction study.

LAGGED_DISPERSION
●
Use in the analysis: Control variable.
●
Description from the original study: “Because past dispersion is likely to affect current
dispersion, we include the lagged dependent variable in each regression.” (page 821)
●
Variables used in the replication:
○
DISPERSION
●
LAGGED_DISPERSION corresponds to the lagged dispersion.
●
No deviations between the original study and the replication/reproduction study.
18. Indices
RR TEAM INSTRUCTIONS: If any of the measured variables described in Section 17 will be
combined into a composite measure (including simply a mean), describe in detail what
measures you will use and how they will be combined. Please be sure this preregistration
includes a link to a clearly commented script that constructs the index according to the narrative.
Specific points to keep in mind (please also consult the Reviewer Criteria):
●
Does the preregistration specify each of the composite measures (e.g. mean scores,
factor scores) that are needed for the focal analysis, and which of the measured
variables in Section 17 are used in each one (e.g. the happiness, joy, and satisfaction
items will be used to create the ‘positive feelings’ measure)?
●
Does the preregistration link to a clearly commented script that constructs the indices
according to the narrative description?
The dependent variable, DISPERSION, is the distance between the policy positions of
the two most extreme parties in the party system. The policy positions are obtained using the
variables:
○
per303 (government and administrative efficiency)
○
per401 (free enterprise)
○
per402 (incentives)
○
per403 (market regulation)
○
per404 (economic planning)
○
per407 (protectionism, negative)
○
per412 (controlled economy),
○
per413 (nationalization)
○
per414 (economic orthodoxy)
○
per504 (welfare state expansion)
○
per505 (welfare state limitation)
○
per701 (labor groups, positive)
Lines 86 to 125 of the Stata do-file “Andrews-Money_Replication_5_Random_Sample.do”
construct the DISPERSION variable for the replication, and lines 87 to 126 of the Stata do-file
“Andrews-Money_Reproduction_5_Random_Sample.do” for the reproduction.

Analysis Plan
19. Statistical models
RR TEAM INSTRUCTIONS: This section should describe in detail the analysis that will be
performed to replicate the focal result. This analysis must align as closely as possible with the
original study’s analysis, even if you have identified limitations in the original study. The level of
detail should allow anyone to reproduce your analyses from your description below. Examples
of what should be specified: the model; each variable; adjustments made to the standard errors
and to case weighting; additional analyses that are required to set up the focal analysis; and the
software used.
Beyond the replication of the focal analysis from the original study, it is at your discretion to test
the claim using other analytic approaches as a check of the robustness of the claim. The
original test should be listed first and be clearly distinguished from any other tests. If you are
testing additional confirmatory hypotheses, describe them in the same order as you numbered
them in the “Hypotheses” section above and make clear reference to the specific hypothesis
being tested for each.
Please provide a link to a clearly commented script that performs the analysis described in the
narrative provided below. Our preference is that this be either an R script or a script from
another language that similarly allows for open and reproducible analyses. Please let the
SCORE team know if this is not possible.
For each analysis specified in section 15 (and particularly the analyses labeled as ‘focal’),
please test that the code runs without error on a random subset of 5% of the relevant data.
When more than one analysis is listed in section 15, this could require separate 5% samples
(e.g. a replication sample and a reproduction sample). Please provide verification that the code
has produced sensible results by providing a screenshot(s) of the output (please upload the
screenshot(s) to the OSF as well). Finally, please confirm that you have only developed and
tested your analysis plan and code using 5% of the dataset (noting that that could be 5% of the
replication observations; 5% of the reproduction observations; and/or 5% of the combined
observations, as relevant).
Specific points to keep in mind (please also consult the Reviewer Criteria):
●
Does the preregistration specify which statistical model will be used to provide the ‘focal
evidence’ for the SCORE test (e.g. a regression coefficient in a larger multiple regression
model), and does it correspond closely to the model and evidence from the original
study?
●
Does the preregistration describe each variable that will be included in the focal analysis,
and what role each variable has (e.g. dependent variable, independent variable)?

●
Does the preregistration include a detailed specification of the focal analysis, including
interactions, lagged terms, controls, etc., in both narrative form and in a clearly
commented script?
●
Does the preregistration verify that the code runs without error on a random subset of
the replication dataset? Is there a separate verification for each analysis specified in
section 15?
This statement confirms that only 5% of the data have been randomly sampled in
developing the analysis plan and code contained in this preregistration.
According to Section 15, “Stopping rule”, two types of analyses are performed: a replication and
a reproduction. The replication uses all available observations, while the reproduction is
restricted to observations that were used in the original study.
For
the
replication,
lines
155
to
166
of
the
Stata
do-file
“Andrews-Money_Replication_5_Random_Sample.do” draw a random sample of 5% of the
countries. For the reproduction, the corresponding lines are 156 to 167 of the Stata do-file
“Andrews-Money_Reproduction_5_Random_Sample.do.”
In both analyses, an Ordinary Least Square (OLS) regression is estimated. The dependent
variable is the natural log of the distance between extreme parties (variable DISPERSION). The
focal independent variable is the natural log of the number of parties in the party system
(variable COUNT_PARTIES). The control variables are:
1.
Single member district systems (SINGLE_MEMBER)
2.
Lagged log dependent variable (LAGGED_DISPERSION)
Moreover, “to account for country-specific variance, we cluster our observations by country”
(page 821).
The
software
used
is
Stata
16.1.
The
analysis
codes
are
“Andrews-Money_Replication_5_Random_Sample.do”
(for
the
replication)
and
“Andrews-Money_Reproduction_5_Random_Sample.do” (for the reproduction), and the log file
with
the
Stata
session
that
demonstrates
that
this
code
works
is
“Andrews-Money_Replication_5_Random_Sample.smcl”
(pdf
version:
“Andrews-Money_Replication_5_Random_Sample.pdf”)
and
“Andrews-Money_Reproduction_5_Random_Sample.smcl”
(pdf
version:
“Andrews-Money_Reproduction_5_Random_Sample.pdf”).
20. Transformations
RR TEAM INSTRUCTIONS: This section should describe how any of the measured variables or
composite measures mentioned above will be transformed prior to the analyses listed in Section

19. These are adjustments made to variables after measurement or measure creation, and
might include centering, logging, lagging, rescaling etc. Please provide enough detail such that
anyone else could reproduce the transformations based on the description below. Please be
sure this preregistration includes a link to a clearly commented script that performs the
transformations described in the narrative provided below.
Specific points to keep in mind (please also consult the Reviewer Criteria):
●
Does the preregistration specify which of the measured variables or composite
measures will need to be transformed prior to the focal analysis?
●
For each variable needing transformation, does the preregistration adequately describe
the transformations, including any centering, logging, lagging, recoding, or
implementation of a coding scheme for categorical variables?
●
Does the preregistration link to a clearly commented script that performs each
transformation?
According to the original paper, “Our two variables of interest – dispersion and number of
parties in the party system – are both skewed. Therefore, we take the natural log of each
variable and use these transformed variables in our regression analysis.” (page 821)”
Therefore, the OLS regressions consider the natural log of DISPERSION and
COUNT_PARTIES
For the replication, lines 81 to 84, and 122 to 125 of the Stata do-file
“Andrews-Money_Replication_5_Random_Sample.do” take the natural log of
COUNT_PARTIES and DISPERSION, respectively. For the reproduction, the corresponding
lines are 82 to 85 and 123 to 126 of the Stata do-file
“Andrews-Money_Reproduction_5_Random_Sample.do.”
21. Inference criteria
RR TEAM INSTRUCTIONS: This section describes the precise criteria that will be used to
assess whether the hypotheses listed above were confirmed by the analyses in Section 19. The
default language below only applies to the test of the SCORE claim, H*. It is at your discretion to
describe the inferential criteria you will use for any additional analyses. They need not rely on
p-values and/or the same alpha level we have specified for H*. Following section 15, if you are
performing multiple analyses corresponding to different subsets of the data, please specify
whether the same criteria will be used for each analysis (e.g. the same coefficient is expected to
be positive and significant in each subset). If the inference criteria differ across analyses, please
make that clear below.
If the additional analyses will use multiple comparisons, the inference criteria is a question with
few “wrong” answers. In other words, transparency is more important than any specific method
of controlling the false discovery rate or false error rate. One may state an intention to report all

tests conducted or one may conduct a specific correction procedure; either strategy is
acceptable.
According to Section 15, “Stopping rule”, two analyses are performed:
●
One analysis that uses all available observations. This will be the focal analysis of the
replication study:
Criteria for a successful replication attempt for the SCORE project is a statistically
significant effect for the predictor COUNT_PARTIES (alpha = .05, two tailed) in the same
pattern as the original study on the focal hypothesis test (H*).
●
A second analysis that only uses observations that were used in the original analysis.
This will be the focal reproduction analysis of the study:
Criteria for a successful reproduction attempt for the SCORE project is a statistically
significant effect for the predictor COUNT_PARTIES (alpha = .05, two tailed) in the same
pattern as the original study on the focal hypothesis test (H*).
In both cases, to test the SCORE claim, H*, that on the economic policy dimension, the number
of parties in the party system is positively associated with policy dispersion, an Ordinary least
squares (OLS) regression is estimated. Following Andrews & Money (2009, page 821) the
specification takes the form:
𝐷𝐼𝑆𝑃𝐸𝑅𝑆𝐼𝑂𝑁𝑖,𝑡=  δ + γ𝐶𝑂𝑈𝑁𝑇_𝑃𝐴𝑅𝑇𝐼𝐸𝑆𝑖,𝑡+ β𝑋𝑖,𝑡          (1)
Where:
1.
is the natural log of the distance between extreme parties along the
𝐷𝐼𝑆𝑃𝐸𝑅𝑆𝐼𝑂𝑁𝑖,𝑡
economic dimension. It is the dependent variable.
2.
is the natural log of the count of parties in the system. It is the focal
𝐶𝑂𝑈𝑁𝑇_𝑃𝐴𝑅𝑇𝐼𝐸𝑆𝑖,𝑡
independent variable. The coefficient of interest is
, which indicates how the dispersion
γ
of parties changes with the number of parties in the system.
3.
: constant term.
δ
4.
: vector of control variables for country
during election . The covariates are:
𝑋𝑖,𝑡
𝑖
𝑡
1.
𝑆𝐼𝑁𝐺𝐿𝐸_𝑀𝐸𝑀𝐵𝐸𝑅𝑖,𝑡
2.
𝐿𝐴𝐺𝐺𝐸𝐷_𝐷𝐼𝑆𝑃𝐸𝑅𝑆𝐼𝑂𝑁𝑖,𝑡
5.
: vector of coefficients for
β
 𝑋𝑖,𝑡

The reproduction and the replication are based on an OLS regression, and follow specification
(1), however, the difference is in the observations used in each analysis. The replication uses all
the observations, while the reproduction uses the observations from the original study.
Following Andrews & Money (2009, pages 821 and 823), robust standard errors clustered at the
country level are used.
22. Data exclusion
RR TEAM INSTRUCTIONS: The section below should describe the rules you will follow to
exclude collected cases from the analyses described in Section 19. Note that this refers to
exclusions after the creation of the replication dataset; exclusion criteria that prevent a case
from entering the replication dataset in the first place should be detailed in the ‘Data Collection
Procedure’ section above. Please be as detailed as possible in describing the rules you will
follow (e.g. What is the specific definition of outliers you will use? Exactly how many attention
checks does a participant need to fail before their removal from the analytic sample?).
Specific points to keep in mind (please also consult the Reviewer Criteria):
●
Does the preregistration comment on whether any cases included in the replication
dataset will be excluded prior to data analysis?
●
If yes, does the preregistration provided detailed instructions on how the exclusions will
be performed (e.g. Is the definition of outlier provided? Is the number of attention checks
failed before a participant is excluded specified?)
Following the original study, “To be included in our measure, a party must have gained at least 1
per cent of the seats in parliament in at least two consecutive elections. If a party fails to gain 1
per cent of the seats in three subsequent (and consecutive) elections, we drop it from our
measure.” (page 810)
Moreover, observations can be excluded from the analysis due to missing values, as will be
described in the “Missing data” section.
23. Missing data
RR TEAM INSTRUCTIONS: The section below should describe how missing or incomplete data
will be handled. Please be as detailed as possible in describing the exact procedures you will
follow (e.g. last value carried forward; mean imputation) and any software required (e.g. We will
use Amelia II in R to perform the imputation).
Specific points to keep in mind (please also consult the Reviewer Criteria):
●
Does the preregistration comment on how missing or incomplete data will be addressed
(e.g. casewise removal, missing data imputation)?

●
If applicable, does the preregistration specify how many missing variables will lead to a
case’s removal (e.g. If a subject does not complete any of the three indices of tastiness,
that subject will not be included in the analysis.)?
●
If applicable, does the preregistration describe how missing data imputation will be
performed, including relevant software?
As described in “Section 12. Data collection procedures,” for the case of SINGLE_MEMBER
variable, missing values for elections before 1960 and after 2017 were single imputed with the
value corresponding to the closest year available in the CPDS. This is possible because
electoral rules tend to be stable within a country, as the original study points out (p.813).
For cases when any of the other variable values are missing, the observation is excluded from
the Ordinary Least Squares regression described in the “Inference Criteria” section.
24. Exploratory analysis (Optional)
RR TEAM INSTRUCTIONS: If you plan to explore your data set to look for unexpected
differences or relationships, you may describe those tests here. An exploratory test is any test
where a prediction is not made up front, or there are multiple possible tests that you are going to
use. A statistically significant finding in an exploratory test is a great way to form a new
confirmatory hypothesis, which could be registered at a later time. If any exploratory analyses
involve additions to the data collection procedure beyond what was performed in the original
study (e.g. additional items on the survey; running another condition in the experiment), please
describe them below.
25. Other
RR TEAM INSTRUCTIONS: This section serves two purposes. First, please use this section to
discuss any features of your replication plan that are not discussed elsewhere. Literature cited,
disclosures of any related work such as replications or work that uses the same data, plans to
make your data and materials public, or other context that will be helpful for future readers
would be appropriate here. Second, please also re-surface any major deviations from earlier in
the preregistration that you expect a reasonable reviewer could flag for concern. Give a
summary of these deviations, focusing on larger changes and any possible challenges for
comparing the results of the original and replication study.
Specific points to keep in mind (please also consult the Reviewer Criteria):
●
Does the preregistration reference other sections of the preregistration where substantial
deviations from the original study have been described (including deviations due to
differences in location or time compared to the original study)?
●
Does the preregistration comment on plans to make the data and materials from the
replication study public?

Final review checklist
REVIEWER INSTRUCTIONS: For the following questions, reviewers please indicate whether
you can ‘sign off’ on the following items by adding a comment. You can update this response as
the lab moves through revisions during the review period!
●
Included in this pre-registration are specific materials needed to create a replication
dataset:
○
Is the final replication dataset that the research team constructed suitable for
performing a high-quality, good-faith replication of the focal claim selected from
the original study?
○
Is the procedure for constructing the final replication dataset sufficiently
documented that an independent researcher could construct the same dataset
following the procedures and code they lay out?
●
Included with this pre-registration is a narrative description of how the replication dataset
will be used to perform the focal replication analysis, as well as the specific analytic
scripts/code/syntax that will be used:
○
Is the analysis plan (including code) that’s documented in the preregistration
consistent with a high-quality, good-faith replication of the focal claim selected
from the original study?
○
Has the data analyst demonstrated that the analysis code works as expected on
a random 5% of the final replication dataset?
●
I have reviewed all sections of this pre-registration, and I believe it represents a
good-faith replication attempt of the original focal claim.
Additionally, please consider the following if the preregistration includes a reproduction
analysis:
●
The observations used for the reproduction analysis were collected and measured in the
same way as the original study.
●
The observations used for the reproduction analysis were analyzed in the same way as
the original study.
●
The data analyst has demonstrated that their analysis code works as expected on a
random 5% of the reproduction data.
●
I believe this preregistration represents a good-faith reproduction attempt of the original
focal claim.

=== END OF REFERENCE JSON WITH THE CORRECT INFO ===

Please return your evaluation as a JSON object where each key is a specific component from the original JSON. For example:
{
    "hypothesis": {
    "score": [your scoring according to the instruction],
    "explanation": [reasoning for your scoring.]
    },
    "data_plan.source_type": {
    "score": [your scoring according to the instruction],
    "explanation": [reasoning for your scoring.]
    },
    ...
}
Output Requirements:\n- Return a valid JSON object only.\n- Do NOT wrap the output in markdown (no ```json).\n- Do NOT include extra text, commentary, or notes.\n\n Ensure accuracy and completeness.\n- Strictly use provided sources as specified.


