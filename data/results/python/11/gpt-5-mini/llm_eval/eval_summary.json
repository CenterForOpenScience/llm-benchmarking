{
  "extract": {
    "aspect_scores": {
      "claim": 0.6,
      "data": 0.7777777777777778,
      "method": 0.6666666666666666,
      "results": 0.18518518518518517,
      "metadata": 1.0
    },
    "avg_score": 0.6459259259259259
  },
  "design": {
    "aspect_scores": {
      "hypothesis": 0.6666666666666666,
      "study_type": 1.0
    },
    "avg_score": 0.8333333333333333
  },
  "execute_design": {
    "aspect_scores": {
      "environment": 0.5,
      "dependecy": 1.0,
      "file_system": 0.3333333333333333
    },
    "avg_score": 0.611111111111111
  },
  "execute_execute": {
    "aspect_scores": {
      "code_execution": 0.0,
      "execution_report": 0.0
    },
    "avg_score": 0.0
  },
  "interpret": {
    "aspect_scores": {
      "interpretation_summary": 0.6666666666666666,
      "execute_status": 0.0,
      "fidelity_assessment": 0.9259259259259259,
      "results_comparison": 1.0,
      "replication_report": 1.0,
      "notes": 1.0,
      "failure_handling_avg": 1.0
    },
    "avg_score": 0.8592592592592592
  }
}