{
  "replication_study": {
    "hypothesis": "Imports from the South (lagged by one year) are positively associated with National Affluence (NAff = gdp / pop). Specifically, the coefficient on lagged Imports-from-the-South (L_IMS) will be > 0 and statistically significant at conventional levels.",
    "study_type": "Observational (country-year panel)",
    "data_plan": {
      "dataset_identifier": "./data/original/10/python/replication_data/finaldata_noNA.csv (local copy included in repository)",
      "source_type": "Assembled international panel (compiled database / merged administrative sources; provided as CSV)",
      "wave_or_subset": "Available years in provided CSV: 1965-2018 (full subset will be used initially). The original paper used 1970-2003; we will run both (a) the full CSV as provided and (b) a restricted sample to 1970-2003 as a robustness check.",
      "sample_size": "Initial raw observations in CSV: 784 rows (country-year). Final estimation sample will be smaller after (i) outlier removal, (ii) removal of first-year lags per country, and (iii) any additional listwise deletions; the script writes exact final N to output.",
      "unit_of_analysis": "Country-year (national-level observations over time).",
      "access_details": "Data file is included in the repository at ./data/original/10/python/replication_data/finaldata_noNA.csv. No external access required for this replication (file included).",
      "qualification": {
        "explanation": "This dataset contains the variables required to operationalize the focal test in the original study: GDP and population to construct national affluence (NAff), total imports to construct Imports-from-the-South (IMS) using the same scaling as the original .do, and unemployment to use as a control. The provided Stata .do (replication_data/KMYR.do) defines NAff and IMS the same way we implement them, confirming high fidelity. See: replication_data/KMYR.do (variable construction lines) and post_registration.json (method & variable descriptions).",
        "similarity_to_original": "High-fidelity elements: (1) Variable definitions match the original .do: NAff = gdp/pop and IMS = totalimport/(gdp*10000) (see replication_data/KMYR.do). (2) Unit and panel structure match the original (country-year panel) and the original method description (post_registration.json describes country-year panel of OECD countries). Files: ./data/original/10/python/replication_data/finaldata_noNA.csv (data columns: country, year, gdp, pop, unemp, totalimport, totalexport) and ./data/original/10/python/replication_data/KMYR.do (Stata commands).",
        "deviation_from_original": "Deviations: (1) Time coverage differs: provided CSV spans 1965-2018 (see CSV year variable summary), whereas the original paper's main analysis used 1970-2003 (post_registration.json). (2) Original estimation used FE-GLS (xtgls) to correct for serial correlation, spatial correlation, and heteroskedasticity; our translated script implements OLS with country fixed effects via dummies and does not fully replicate FE-GLS corrections. (3) The original used Hadi outlier detection; MinCovDet is used here as a robust multivariate outlier approximation (scikit-learn) which may not exactly match Hadi's exact flagged observations. References: post_registration.json (original methods and FE-GLS), replication_data/KMYR.do (Hadi call hadimvo ...), and the Python script written to replication_data/KMYR__py.py (outlier approach and modeling choices)."
      },
      "notes": "Notes / caveats: (1) The original used FE-GLS (xtgls) with panel corrections and spatial correlation; our Python implementation currently fits OLS with fixed effects (country dummies) and 5-year dummies; reproducing FE-GLS with the same corrections would require implementing panel GLS and spatial correlation structure in Python or running Stata. (2) Outlier detection: Hadi was used originally; the script uses MinCovDet-based Mahalanobis p-values as an approximation (results may differ slightly). (3) The script expects the repository to be mounted at /app/data so that the input path /app/data/original/10/python/replication_data/finaldata_noNA.csv is accessible. (4) Column types appear standard (no unusual encoding), but the script will drop rows with missing lagged regressors (listwise deletion)."
    },
    "planned_method": {
      "steps": [
        "1) Use /app/data/original/10/python/replication_data/finaldata_noNA.csv as input. Confirm columns: country, year, countryyear, gdp, pop, unemp, totalimport, totalexport.",
        "2) Construct variables exactly as in the .do: NAff = gdp/pop; IMS = totalimport/(gdp*10000); EXS = totalexport/(gdp*10000).",
        "3) Detect and remove outliers using a robust multivariate method approximating Hadi (MinCovDet Mahalanobis + p-value threshold).",
        "4) Create 5-year period dummy variables (DUM70to74 ... DUM15to18) as in the .do.",
        "5) Sort by country and year and compute one-year lags of IMS, EXS, and unemp within each country.",
        "6) Drop rows missing lagged regressors (listwise deletion for model sample).",
        "7) Estimate the focal model: NAff ~ L_IMS + L_EXS + L_unemp + country fixed effects + 5-year dummies (OLS with dummy fixed effects).",
        "8) Save full regression summary and coefficient table (estimates, SEs, t-stats, p-values) to /app/data for review, and compare the coefficient on L_IMS to the original reported b=.910, SE=.104, p<.001.",
        "9) Sensitivity checks: (a) Restrict sample to years 1970-2003 to match original; (b) attempt GLS/correction methods if desired (note: more advanced panel corrections require extra implementation)."
      ],
      "models": "Primary model: OLS with country fixed effects (implemented via country dummies) and period (5-year) dummies. The original used FE-GLS (xtgls) with corrections for autocorrelation and cross-sectional correlation; this is noted as a methodological difference. Optional: implement generalized least squares / panel-corrected standard errors if necessary.",
      "outcome_variable": "NAff (national affluence) defined as gdp / pop.",
      "independent_variables": "Primary: L_IMS (one-year lag of Imports from the South, IMS = totalimport/(gdp*10000)). Secondary: L_EXS (lagged exports to South), L_unemp (lagged unemployment).",
      "control_variables": "Country fixed effects (C(countrynum) in the model), 5-year period dummies (DUM70to74 ... DUM15to18).",
      "tools_software": "Python 3.10+, packages: pandas, numpy, scikit-learn, scipy, statsmodels, patsy. Script path: ./data/original/10/python/replication_data/KMYR__py.py.",
      "planned_estimation_and_test": {
        "estimation": "Target of estimation: coefficient (beta) on L_IMS (lagged Imports from the South). We'll report estimate, standard error, t-statistic, and p-value.",
        "test": "Null hypothesis H0: beta_L_IMS = 0. Test via t-test from OLS output (two-sided by default; we will evaluate statistical significance and sign)."
      },
      "missing_data_handling": "Listwise deletion for the estimation model (drop rows with missing lagged regressors or missing NAff). Missingness is introduced by lagging (first year per country) and by outlier removal; the script reports final sample size.",
      "multiple_testing_policy": "Primary focus is a single focal coefficient (L_IMS). No multiple-testing correction planned for the primary test. If multiple outcomes or multiple related hypotheses are tested, apply Bonferroni or Benjamini-Hochberg as appropriate and report both unadjusted and adjusted p-values.",
      "inference_criteria": "Primary inference: two-sided p < 0.05 is treated as statistically significant; directionality (positive sign) is part of substantive hypothesis (we will also report exact p-values). For direct comparison to the original reported b=.910 (SE=.104, p<.001), we will compare estimate and SE magnitude and sign. Note that differences in estimation method (OLS FE vs FE-GLS) or outlier detection can change SEs; interpret differences accordingly."
    },
    "codebase": {
      "files": {
        "replication_data/KMYR__py.py": "Python translation of the original Stata .do (KMYR.do). Reads the CSV at /app/data/original/10/python/replication_data/finaldata_noNA.csv, constructs NAff, IMS, EXS, applies robust outlier detection (MinCovDet approximation to Hadi), generates 5-year dummies, lags IMS, EXS, unemp within countries, fits OLS with country fixed effects and 5-year dummies, and writes outputs to /app/data/replication_results.txt and /app/data/replication_coef.csv. This file is the primary executable entrypoint for replication in Python.",
        "replication_data/finaldata_noNA.csv": "Primary dataset (CSV) used by the analysis. Contains columns: country, year, countryyear, gdp, pop, unemp, totalimport, totalexport. This is read by KMYR__py.py. (Included but not executed as code.)",
        "replication_data/KMYR.do": "Original Stata script included for reference. Not executed, but used to guide variable definitions and model specification. The Python rewrite preserves the variable definitions and broad modeling intent. See lines constructing NAff, IMS, EXS and the xtgls model call."
      },
      "notes": "Notes on code design and runtime: (1) All IO in the Python script uses absolute paths starting with /app/data to conform to the execution environment. (2) The Python script approximates Hadi outlier detection with MinCovDet-based Mahalanobis distance; exact replication of Hadi would require a dedicated Hadi implementation. (3) The original FE-GLS corrections (xtgls with panels(hetero) corr(psar1) force) are not implemented; users who require identical estimation can either run the original KMYR.do in Stata or extend the Python code to use GLS / panel-corrected inference packages. (4) The repository must be mounted so /app/data/original/10/python/replication_data/finaldata_noNA.csv is accessible to the container or runtime."
    },
    "docker_specs": {
      "base_image": "python:3.10-slim",
      "packages": {
        "python": [
          "pandas==1.5.3",
          "numpy==1.23.5",
          "scikit-learn==1.2.2",
          "scipy==1.10.1",
          "statsmodels==0.14.0",
          "patsy==0.5.3"
        ],
        "other": [
          "git",
          "wget",
          "make"
        ]
      },
      "hardware": {
        "gpu_support": "false",
        "min_gpu_memory_gb": "0",
        "min_ram_gb": "4"
      },
      "volumes": [
        "./data:/app/data"
      ]
    },
    "analysis": {
      "instructions": "1) Ensure repository is mounted at /app/data (./data mapped to /app/data). 2) Install required Python packages inside container/environment. 3) Run the Python entrypoint: python /app/data/original/10/python/replication_data/KMYR__py.py. 4) Inspect output files: /app/data/replication_results.txt (full regression summary), /app/data/replication_coef.csv (coefficient table). 5) Compare the coefficient of L_IMS to the original focal result (original: b = 0.910, SE = 0.104, p < .001 per initial_details.txt). 6) Run robustness checks: restrict data to years 1970-2003, re-run script (modify code or filter before modeling), and optionally implement panel-corrected GLS to approximate original xtgls results.",
      "comparison_metrics": "Metrics to compare original vs replication: (1) Estimate of the focal coefficient (beta_L_IMS) and its sign; (2) Standard error of beta_L_IMS; (3) t-statistic and p-value for beta_L_IMS; (4) Magnitude ratio (replication_estimate / original_estimate) and difference in SEs; (5) Changes in sample size and years used; (6) Robustness: estimates under restricted sample (1970-2003) and under alternative outlier thresholds or estimation methods (if added)."
    }
  }
}