{
  "extract": {
    "aspect_scores": {
      "claim": 0.5555555555555556,
      "data": 0.6666666666666666,
      "method": 0.5714285714285714,
      "results": 0.5555555555555556,
      "metadata": 1.0
    },
    "avg_score": 0.6698412698412699
  },
  "design": {
    "aspect_scores": {
      "hypothesis": 0.6666666666666666,
      "study_type": 1.0,
      "data_plan": 0.5333333333333333,
      "planned_method": 0.7777777777777778
    },
    "avg_score": 0.7444444444444445
  },
  "execute_design": {
    "aspect_scores": {
      "environment": 1.0,
      "dependecy": 1.0,
      "file_system": 1.0
    },
    "avg_score": 1.0
  },
  "execute_execute": {
    "aspect_scores": {
      "code_execution": 1.0,
      "execution_report": 1.0
    },
    "avg_score": 1.0
  },
  "interpret": {
    "aspect_scores": {
      "interpretation_summary": 0.6666666666666666,
      "execute_status": 1.0,
      "fidelity_assessment": 0.4444444444444444,
      "results_comparison": 0.9166666666666666,
      "replication_report": 0.6666666666666666,
      "failure_handling[0]": 0.3333333333333333,
      "notes": 0.3333333333333333
    },
    "avg_score": 0.6230158730158729
  }
}