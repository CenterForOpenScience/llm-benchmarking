import base64
from openai import OpenAI
import os
import json
import pandas as pd
import pyreadr
from core.constants import API_KEY
from typing import Dict, Any, Optional, Tuple
import io # Add this import at the top of your file
from pathlib import Path
import difflib

from pypdf import PdfReader

client = OpenAI(api_key=API_KEY)

class DataFrameAnalyzer:
    """
    A class to load and analyze a tabular dataset from a file.

    Loads a DataFrame once upon initialization and provides methods
    to perform common exploratory analysis tasks.
    """
    def __init__(self, file_path: str):
        """
        Initializes the analyzer and loads the data.

        Args:
            file_path (str): The path to the CSV file.
        """
        self.file_path = file_path
        self.df: Optional[pd.DataFrame] = self._load_data()

    def _load_data(self) -> Optional[pd.DataFrame]:
        """
        Private method to load data from the file_path.
        Handles both .csv, .xlsx, and .dta files and potential errors.
        """
        # Get the file extension from the file path
        _, file_extension = os.path.splitext(self.file_path)
        
        try:
            print(f"Loading data from {self.file_path}...")
            
            # Choose the correct pandas function based on the extension
            if file_extension == '.csv':
                return pd.read_csv(self.file_path)
            elif file_extension in ['.xlsx', '.xls']:
                # You might need to install openpyxl: pip install openpyxl
                return pd.read_excel(self.file_path)
            elif file_extension == '.dta':
                return pd.read_stata(self.file_path)
            elif file_extension.lower() == '.rds':
                return pyreadr.read_r(self.file_path)[None]
            else:
                print(f"Error: Unsupported file type '{file_extension}'.")
                return None

        except FileNotFoundError:
            print(f"Error: The file at {self.file_path} was not found.")
            return None
        except (pd.errors.ParserError, ValueError, Exception) as e:
            # Catch pandas parsing errors and other potential issues
            print(f"An error occurred while reading the file: {e}")
            return None

    def get_head(self, n: int = 5) -> Optional[pd.DataFrame]:
        """Returns the first n rows of the DataFrame."""
        if self.df is not None:
            return self.df.head(n)
        return None

    def get_shape(self) -> Optional[Tuple[int, int]]:
        """Returns the shape (rows, columns) of the DataFrame."""
        if self.df is not None:
            # .shape is an attribute, not a function
            return self.df.shape
        return None

    def get_info(self) -> str: # Change the return type hint to str
        """
        Returns a concise summary of the DataFrame as a string.
        """
        if self.df is not None:
            # Create an in-memory text buffer
            buffer = io.StringIO()
            
            # Tell df.info() to write its output to the buffer instead of the console
            self.df.info(buf=buffer)
            
            # Get the string from the buffer and return it
            return buffer.getvalue()
        return "Error: DataFrame not loaded."

    def get_description(self) -> Optional[pd.DataFrame]:
        """Returns descriptive statistics of the DataFrame."""
        if self.df is not None:
            return self.df.describe()
        return None
    
def load_dataset(session_state: Dict[str, Any], file_path: str) -> str:
    """
    Loads a dataset and stores its analyzer in the session state.
    """
    analyzers = session_state["analyzers"]
    if file_path in analyzers:
        return f"Dataset '{file_path}' is already loaded."
    
    analyzer = DataFrameAnalyzer(file_path)
    if analyzer.df is not None:
        analyzers[file_path] = analyzer
        return f"Successfully loaded dataset '{file_path}'."
    else:
        return f"Failed to load dataset from '{file_path}'."

def get_dataset_shape(session_state: Dict[str, Any], file_path: str) -> str:
    """
    Gets the shape from an analyzer in the session state.
    """
    analyzers = session_state["analyzers"]
    if file_path not in analyzers:
        return "Error: Dataset not loaded. Please call load_dataset() first."
    return str(analyzers[file_path].get_shape())

def get_dataset_head(session_state: Dict[str, Any], file_path: str) -> str:
    analyzers = session_state["analyzers"]
    if file_path not in analyzers:
        return "Error: Dataset not loaded. Please call load_dataset() first."
    return str(analyzers[file_path].get_head())

def get_dataset_info(session_state: Dict[str, Any], file_path: str) -> str:
    analyzers = session_state["analyzers"]
    if file_path not in analyzers:
        return "Error: Dataset not loaded. Please call load_dataset() first."
    return str(analyzers[file_path].get_info())

def get_dataset_description(session_state: Dict[str, Any], file_path: str) -> str:
    analyzers = session_state["analyzers"]
    if file_path not in analyzers:
        return "Error: Dataset not loaded. Please call load_dataset() first."
    return str(analyzers[file_path].get_description())

def read_image(file_path):
    # Function to encode the image
    def encode_image(image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode("utf-8")
    base64_image = encode_image(file_path)
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0,
        messages=[
            {
                "role": "user",
                "content": [
                    { "type": "text", "text": "Describe this image in details." },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}",
                        },
                    },
                ],
            }
        ])
    return completion.choices[0].message.content



def ask_human_input(question_to_ask: str) -> str:
    """
    Prompts the human user for input in the terminal.

    Use this tool when you are stuck, need clarification, or require 
    information that you cannot find or deduce from the available files.

    Args:
        question_to_ask (str): The clear, specific question to ask the human user.

    Returns:
        str: The human's response from the terminal.
    """
    # Print a clear message to the user indicating the agent needs help
    print("\nðŸ¤” [AGENT NEEDS HUMAN INPUT] ðŸ¤”")
    print(f"Agent's Question: {question_to_ask}")
    
    # Get input from the user
    human_response = input("Your Response: ")
    
    return human_response


def list_files_in_folder(folder_path: str) -> str:
    """
    Lists all files within a specified folder and returns their names as a single string,
    with each file separated by a comma.

    Args:
        folder_path: The absolute or relative path to the folder.

    Returns:
        A string containing the names of all files in the folder,
        each separated by a newline character. If the folder does not exist
        or is not a directory, an error message is returned.
    """
    # Check if the provided path exists
    if not os.path.exists(folder_path):
        return f"Error: Folder '{folder_path}' does not exist."

    # Check if the provided path is actually a directory
    if not os.path.isdir(folder_path):
        return f"Error: Path '{folder_path}' is not a directory."

    file_names = []
    # Iterate over all entries in the folder
    for entry in os.listdir(folder_path):
        # Construct the full path to the entry
        full_path = os.path.join(folder_path, entry)
        # Check if the entry is a file (and not a subdirectory)
        if os.path.isfile(full_path):
            file_names.append(entry)

    # Sort the file names alphabetically for consistent output
    file_names.sort()
    
    file_info = f"Folder path: {folder_path}\n"
    file_info += f"All files: {', '.join(file_names)}"
    return file_info
from pathlib import Path

def write_file(file_path: str, file_content: str, overwrite: bool = False) -> str:
    """
    Create a NEW file (default) or overwrite an existing file only if overwrite=True.
    """
    full_path = Path.cwd() / file_path

    file_exists = full_path.exists()

    print("\nðŸ“ [AGENT ASKS TO WRITE FILE] ðŸ“")
    print(f"FULL PATH: {full_path}")
    print(f"EXISTS ALREADY?: {file_exists}")
    print(f"OVERWRITE FLAG?: {overwrite}")
    print(f"FILE CONTENT:\n---\n{file_content}\n---")

    if file_exists and not overwrite:
        msg = (
            "âŒ Refusing to overwrite an existing file. "
            "Use edit_file(...) for targeted edits, or call write_file(..., overwrite=True)."
        )
        print(msg)
        return msg

    user_response = input("Do you approve? (yes/no): ")
    if user_response.lower().strip() != "yes":
        print("âŒ User denied execution.")
        return f"Command execution denied by the user:\n{user_response}"

    try:
        full_path.parent.mkdir(parents=True, exist_ok=True)
        with open(full_path, "w", encoding="utf-8") as f:
            f.write(file_content)
        success_message = f"âœ… Successfully wrote content to {full_path}"
        print(success_message)
        return success_message
    except Exception as e:
        error_message = f"âŒ Error writing file to {full_path}: {e}"
        print(error_message)
        return error_message


def read_file(file_path: str, max_chars: int = 20000) -> str:
    """
    Read a text file (truncated) so the agent can make targeted edits.
    """
    full_path = Path.cwd() / file_path

    if not full_path.exists():
        return f"Error: File not found: {full_path}"
    if full_path.is_dir():
        return f"Error: Path is a directory: {full_path}"

    try:
        content = full_path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        content = full_path.read_text(encoding="latin-1")

    if len(content) > max_chars:
        return content[:max_chars] + f"\n\n... [TRUNCATED {len(content)-max_chars} chars] ..."
    return content



def edit_file(
    file_path: str,
    edit_type: str,
    *,
    old_text: str = None,
    new_text: str = None,
    start_marker: str = None,
    end_marker: str = None,
    anchor: str = None,
    insert_text: str = None,
    count: int = 1,
) -> str:
    """
    Targeted edits WITHOUT overwriting the whole file.
    Shows a unified diff and requires approval.

    edit_type:
      - "replace"
      - "replace_between" (markers kept; content between replaced)
      - "insert_after"
      - "insert_before"
      - "append"
      - "prepend"
    """
    full_path = Path.cwd() / file_path

    if not full_path.exists():
        return f"Error: File not found: {full_path}"
    if full_path.is_dir():
        return f"Error: Path is a directory: {full_path}"

    try:
        original = full_path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        original = full_path.read_text(encoding="latin-1")

    edited = original

    if edit_type == "replace":
        if old_text is None or new_text is None:
            return "Error: replace requires old_text and new_text."
        if old_text not in edited:
            return "Error: old_text not found."
        edited = edited.replace(old_text, new_text, count)

    elif edit_type == "replace_between":
        if start_marker is None or end_marker is None or new_text is None:
            return "Error: replace_between requires start_marker, end_marker, and new_text."
        s = edited.find(start_marker)
        if s == -1:
            return "Error: start_marker not found."
        e = edited.find(end_marker, s + len(start_marker))
        if e == -1:
            return "Error: end_marker not found (after start_marker)."
        between_start = s + len(start_marker)
        between_end = e
        edited = edited[:between_start] + new_text + edited[between_end:]

    elif edit_type in ("insert_after", "insert_before"):
        if anchor is None or insert_text is None:
            return f"Error: {edit_type} requires anchor and insert_text."
        idx = edited.find(anchor)
        if idx == -1:
            return "Error: anchor not found."
        insert_at = idx + len(anchor) if edit_type == "insert_after" else idx
        edited = edited[:insert_at] + insert_text + edited[insert_at:]

    elif edit_type == "append":
        if insert_text is None:
            return "Error: append requires insert_text."
        if edited and not edited.endswith("\n"):
            edited += "\n"
        edited += insert_text

    elif edit_type == "prepend":
        if insert_text is None:
            return "Error: prepend requires insert_text."
        edited = insert_text + ("" if insert_text.endswith("\n") else "\n") + edited

    else:
        return f"Error: Unknown edit_type '{edit_type}'."

    if edited == original:
        return "No changes made."

    diff = "\n".join(
        difflib.unified_diff(
            original.splitlines(),
            edited.splitlines(),
            fromfile=str(full_path) + " (before)",
            tofile=str(full_path) + " (after)",
            lineterm="",
        )
    )

    print("\nâœï¸ [AGENT PROPOSES A FILE EDIT] âœï¸")
    print(f"FULL PATH: {full_path}")
    print(f"DIFF:\n---\n{diff}\n---")

    user_response = input("Do you approve this edit? (yes/no): ")
    if user_response.lower().strip() != "yes":
        print("âŒ User denied edit.")
        return f"Edit denied by the user:\n{user_response}"

    try:
        full_path.write_text(edited, encoding="utf-8")
        msg = f"âœ… Successfully edited {full_path}"
        print(msg)
        return msg
    except Exception as e:
        return f"âŒ Error writing edited file to {full_path}: {e}"

def read_and_summarize_pdf(file_path: str) -> str:
    """
    Reads a PDF file. If the PDF is short (<= 15 pages), it returns the full text.
    If the PDF is long (> 15 pages), it splits the text into chunks and uses the
    LLM to summarize each chunk, returning a consolidated summary to save context window.

    Args:
        file_path (str): Path to the PDF file.

    Returns:
        str: Full text or a consolidated summary of the PDF.
    """
    if not os.path.exists(file_path):
        return f"Error: File '{file_path}' not found."

    try:
        reader = PdfReader(file_path)
        number_of_pages = len(reader.pages)
        
        # Extract all text first
        full_text = ""
        for page in reader.pages:
            text = page.extract_text()
            if text:
                full_text += text + "\n"
        
        # THRESHOLD: If 15 pages or less, just return the text as is.
        if number_of_pages <= 15:
            print(f"PDF is short ({number_of_pages} pages). Returning full text.")
            return f"--- START OF PDF CONTENT ({number_of_pages} pages) ---\n{full_text}\n--- END OF PDF CONTENT ---"

        # LOGIC FOR LONG PDFS
        print(f"PDF is long ({number_of_pages} pages). Summarizing content to prevent overflow...")
        
        # Split text into chunks of roughly 12,000 characters (approx 3-4k tokens)
        chunk_size = 12000
        chunks = [full_text[i:i+chunk_size] for i in range(0, len(full_text), chunk_size)]
        
        summaries = []
        total_chunks = len(chunks)
        
        for i, chunk in enumerate(chunks):
            print(f"Summarizing chunk {i+1}/{total_chunks}...")
            completion = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "You are a helpful research assistant. Summarize the following text from a technical paper/document. Capture key methodologies, specific metrics, results, and conclusions. Do not lose specific data points."
                    },
                    {
                        "role": "user", 
                        "content": chunk
                    }
                ]
            )
            summaries.append(completion.choices[0].message.content)
            
        consolidated_summary = "\n\n".join(summaries)
        
        return (f"--- PDF SUMMARY (Document was {number_of_pages} pages long) ---\n"
                f"The document was too long to read directly, so here is a detailed summary of all sections:\n\n"
                f"{consolidated_summary}")

    except Exception as e:
        return f"Error reading or summarizing PDF: {e}"