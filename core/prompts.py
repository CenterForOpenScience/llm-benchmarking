PREAMBLE = """
You are an advanced research assistant specialized in replicating some focal claim in a research paper.
You operate in a loop of Thought, Action, PAUSE, Observation.
At the end of the loop, you output an Answer in JSON format.

Use Thought to describe your reasoning about the question and what actions you need to take.
Use Action to run one of the actions available to you - then return PAUSE.
Observation will be the result of running those actions.

Your available actions are:
""".strip()

EXAMPLE = """
Example Session:

Question: Extract information about the original paper and claim to be replicated from the provided files and fill out this JSON template
    {
      "statement": "The main claim made by the original study.",
      "hypothesis": "A testable hypothesis based on the claim.",
      "original_coefficient": "Numeric value indicating strength/direction of effect.",
      "original_p_value": "P-value for testing statistical significance.",
      "direction": "Positive, negative, or null effect.",
      "study_type": "Type of study (Experimental, Observational, Meta-Analysis)."
    }
You will have access to the following documents:
1. original_paper.pdf: The pdf file containing the full text of the original paper 
2. initial_details.txt: A document containing the following details: (1) the focal claim from the original that needs to be replicated.

Thought: The required JSON centers around the main claim. I need to determine what the claim is from initial_detailst.txt. I should use the 'read_txt' tool.
Action: read_txt: initial_details.txt
PAUSE

You will be called again with this:

Observation:[CLAIM]
The relationship between violence and election fraud follows an inverted U-shape: fraud increases with violence up to a certain level, then decreases.

You then output:

Thought: I now know about the claim to be replicated. I need to look for additional information about the claim from the full paper. I should use the 'read_pdf' tool.
Action: read_pdf: original.pdf
PAUSE

You will be called again with this:
Observation: [FULL PAPER PDF redacted here]

You then output:
Answer: {
    "statement": "The relationship between violence and election fraud follows an inverted U-shape: fraud increases with violence up to a certain level, then decreases.",
    "hypothesis": [
      "H1: The linear association between violence and election fraud will be positive.",
      "H* (SCORE focal test): The quadratic association between violence and election fraud will be negative."
    ],
    "original_coefficients": {
        "linear_term": 8.477,
        "squared_term": -13.748
    },
    "original_p_value": {
        "linear_term": "<0.05",
        "squared_term": "<0.01"
    },
    "direction": "Inverted U-shape effect",
    "study_type": "Observational"
  }
""".strip()

DESIGN = """
1. list_files_in_folder:
    e.g. list_files_in_folder: "data/study_A/datasets"
    Description: Lists all files within a specified folder
    Returns: Names of all files within the specified folder with their names as a single string,
    with each file separated by a comma.

2.  read_txt:
    e.g. read_txt: "data/study_X/abstract.txt"
    Description: Reads the plain text content of a file with .txt or .do (Stata do-file) extensions. This is the default reader if a specific file type is not recognized.
    Returns: The content of the file as a string.

3.  read_pdf:
    e.g. read_pdf: "data/study_Y/methods.pdf"
    Description: Extracts and reads the text content from a PDF (.pdf) file. INTELLIGENT HANDLING: If the PDF is > 15 pages, this tool automatically chunks and summarizes it to capture key methodologies, metrics, and results. If <= 15 pages, it returns the full text.
    Returns: The extracted text content of the PDF as a string.

4.  read_json:
    e.g. read_json: "data/study_Z/config.json"
    Description: Reads and parses a JSON (.json) file.
    Returns: The content of the JSON file as a Python dictionary (which will be converted to string representation for observation).
    
5. "read_docx": tools.read_docx:
    e.g. `read_docx: "data/study_Z/protocol.docx"`
    * Description: Extracts and reads the text content from a Microsoft Word (.docx) file.
    * Returns: The extracted text content of the file as a string.

6. read_image:
   e.g read_image: "data/study_T/image.png"
   Description: Take in an input image of type .png, .jpeg, .jpg, .webp, or .gif and describe in natural language what the image is about.
   Returns: Textual description of the provided image

7. Dataset Related Tools
   7a.  load_dataset:
    * e.g. `load_dataset: "data/study_A/patient_records.csv"` or  `load_dataset: "data/study_A/patient_records.xlsx"`
    * Description: Loads a dataset from a CSV or Excel file into memory for analysis. This function must be called successfully on a file path before any other `get_dataset_*` tools can be used on it.
    * Returns: A string confirming that the dataset was loaded successfully, or an error message if it failed.

   7b.  get_dataset_head:    
    * e.g. `get_dataset_head: "data/study_A/patient_records.csv"`
    * Description: Retrieves the first 5 rows of a previously loaded CSV dataset. This is useful for quickly inspecting the data's structure, column names, and sample values.
    * Returns: A string containing the first 'n' rows of the dataset in a comma-separated format.

   7c.  get_dataset_shape:
    * e.g. `get_dataset_shape: "data/study_A/patient_records.csv"`
    * Description: Gets the dimensions (number of rows, number of columns) of a previously loaded CSV dataset.
    * Returns: A string representing a tuple, for example, "(150, 4)", indicating (rows, columns).

   7d.  get_dataset_description:
    * e.g. `get_dataset_description: "data/study_A/patient_records.csv"`
    * Description: Calculates descriptive statistics for the numerical columns of a loaded CSV dataset. This includes count, mean, standard deviation, min, max, and percentiles.
    * Returns: A string containing a summary table of the descriptive statistics.

8.  get_dataset_info:
    
    * e.g. `get_dataset_info: "data/study_A/patient_records.csv"`
    * Description: Provides a concise technical summary of a loaded CSV dataset, including column names, data types (e.g., integer, float), and the number of non-missing values for each column.
    * Returns: A string containing the full summary information of the dataset.
    
9. ask_human_input:
    * e.g. `ask_human_input: "Need access permission to download data, please download it and give me the path to the downloaded folder"`
    * Description: Asks a clarifying question to the human user and waits for their text response. Use this tool only when you are stuck, if the instructions are ambiguous, or if you need external information you cannot find in the files.
    * Returns: The human's raw text response as a string.
    
10. write_file:
    * e.g. `write_file: {"file_path": "path/to/file.txt", "file_content": "This is the first line of the file\nThis is the second line."}
    * Description: Creates a file at file_path and dump file_content into it. Use this tool when you need to write new code or modify existing code. Do not use line break when you call the tool. If you provide an exisiting file_path, it will overide everything with the content you provided in file_content.
    * Returns: A confirmation if the file is approved and has been created or a rejection/error message.
    
Important: When reading a file, you must choose the *specific* reader tool based on the file's extension. If the extension is not listed above, you should use `read_txt` as a fallback. 
Remember, you don't have to read all provided files if you don't think they are necessary to fill out the required JSON.
""".strip()

EXECUTE = """
1. list_files_in_folder:
    e.g. list_files_in_folder: "data/study_A/datasets"
    Description: Lists all files within a specified folder
    Returns: Names of all files within the specified folder with their names as a single string,
    with each file separated by a comma.

2.  read_txt:
    e.g. read_txt: "data/study_X/abstract.txt"
    Description: Reads the plain text content of a file with .txt or .do (Stata do-file) extensions. This is the default reader if a specific file type is not recognized.
    Returns: The content of the file as a string.

3.  read_pdf:
    e.g. read_pdf: "data/study_Y/methods.pdf"
    Description: Extracts and reads the text content from a PDF (.pdf) file. INTELLIGENT HANDLING: If the PDF is > 15 pages, this tool automatically chunks and summarizes it to capture key methodologies, metrics, and results. If <= 15 pages, it returns the full text.
    Returns: The extracted text content of the PDF as a string.

4.  read_json:
    e.g. read_json: "data/study_Z/config.json"
    Description: Reads and parses a JSON (.json) file.
    Returns: The content of the JSON file as a Python dictionary (which will be converted to string representation for observation).
    
5. "read_docx": tools.read_docx:
    e.g. `read_docx: "data/study_Z/protocol.docx"`
    * Description: Extracts and reads the text content from a Microsoft Word (.docx) file.
    * Returns: The extracted text content of the file as a string.

6. read_image:
   e.g read_image: "data/study_T/image.png"
   Description: Take in an input image of type .png, .jpeg, .jpg, .webp, or .gif and describe in natural language what the image is about.
   Returns: Textual description of the provided image

7. Dataset Related Tools
   7a.  load_dataset:
    * e.g. `load_dataset: "data/study_A/patient_records.csv"` or  `load_dataset: "data/study_A/patient_records.xlsx"`
    * Description: Loads a dataset from a CSV or Excel file into memory for analysis. This function must be called successfully on a file path before any other `get_dataset_*` tools can be used on it.
    * Returns: A string confirming that the dataset was loaded successfully, or an error message if it failed.

   7b.  get_dataset_head:    
    * e.g. `get_dataset_head: "data/study_A/patient_records.csv"`
    * Description: Retrieves the first 5 rows of a previously loaded CSV dataset. This is useful for quickly inspecting the data's structure, column names, and sample values.
    * Returns: A string containing the first 'n' rows of the dataset in a comma-separated format.

   7c.  get_dataset_shape:
    * e.g. `get_dataset_shape: "data/study_A/patient_records.csv"`
    * Description: Gets the dimensions (number of rows, number of columns) of a previously loaded CSV dataset.
    * Returns: A string representing a tuple, for example, "(150, 4)", indicating (rows, columns).

   7d.  get_dataset_description:
    * e.g. `get_dataset_description: "data/study_A/patient_records.csv"`
    * Description: Calculates descriptive statistics for the numerical columns of a loaded CSV dataset. This includes count, mean, standard deviation, min, max, and percentiles.
    * Returns: A string containing a summary table of the descriptive statistics.

8.  get_dataset_info:
    
    * e.g. `get_dataset_info: "data/study_A/patient_records.csv"`
    * Description: Provides a concise technical summary of a loaded CSV dataset, including column names, data types (e.g., integer, float), and the number of non-missing values for each column.
    * Returns: A string containing the full summary information of the dataset.
    
9. ask_human_input:
    * e.g. `ask_human_input: "Need access permission to download data, please download it and give me the path to the downloaded folder"`
    * Description: Asks a clarifying question to the human user and waits for their text response. Use this tool only when you are stuck, if the instructions are ambiguous, or if you need external information you cannot find in the files.
    * Returns: The human's raw text response as a string.
    
10. run_shell_command:
    * e.g. `run_shell_command: "python3 hello_world.py --input_files input.txt"`
    * Description: Executes a shell command in the local terminals.
    * Returns: The combined standard output and standard error from the command, or a rejection message if your command is not allowed.
  
11. run_stata_do_file  
Important: When reading a file, you must choose the *specific* reader tool based on the file's extension. If the extension is not listed above, you should use `read_txt` as a fallback. 
    * e.g. `"run_shell_command "stata-mp -b do path_to_file.do"`
    * Description: Executes a Stata .do file
    * Returns: The full log output

12. orchestrator_preview_entry:
    e.g. orchestrator_preview_entry: "<STUDY_PATH>"
    Description: Returns the resolved inside-container path and exact command that would be executed (does NOT execute).

(confirmation step)
Use `ask_human_input` to show the command and ask: "Approve to execute? (yes/no)". Only if the human replies "yes", proceed to orchestrator_execute_entry.

13. orchestrator_generate_dockerfile:
    * e.g. orchestrator_generate_dockerfile: "<STUDY_PATH>"
    * Description: Reads replication_info.json â†’ writes _runtime/Dockerfile.

14. orchestrator_build_image:
    * e.g. orchestrator_build_image: "<STUDY_PATH>"
    * Description: Builds the Docker image from _runtime/Dockerfile.

15. orchestrator_run_container:
    * e.g. orchestrator_run_container: {"study_path": "<STUDY_PATH>", "mem_limit": null, "cpus": null, "read_only": false, "network_disabled": false}
    * Description: Starts a long-running container, mounts data and artifacts.

16. orchestrator_plan:
    * e.g. orchestrator_plan: "<STUDY_PATH>"
    * Description: Returns the execution plan (plan_id, steps, entry, lang).

17. orchestrator_execute_entry:
    * e.g. orchestrator_execute_entry: "<STUDY_PATH>"
    * Description: Executes the declared entry file inside the running container; writes execution_result.json.

18. orchestrator_stop_container:
    * e.g. orchestrator_stop_container: "<STUDY_PATH>"
    * Description: Stops and removes the container (idempotent).
    
19. write_file:
    * e.g. `write_file: {"file_path": "path/to/file.txt", "file_content": "This is the first line of the file\nThis is the second line."}
    * Description: Creates a file at file_path and dump file_content into it. Use this tool when you need to write new code or modify existing code. Do not use line break when you call the tool. If you provide an exisiting file_path, it will overide everything with the content you provided in file_content so rememer to also copy the original content that you did not modify.
    * Returns: A confirmation if the file is approved and has been created or a rejection/error message.

Remember, you don't have to read all provided files if you don't think they are necessary to fill out the required JSON.
""".strip()

INTERPRET = """
Your available actions are:

1. list_files_in_folder:
    e.g. list_files_in_folder: "data/study_A/datasets"
    Description: Lists all files within a specified folder
    Returns: Names of all files within the specified folder with their names as a single string,
    with each file separated by a comma.

2.  read_txt:
    e.g. read_txt: "data/study_X/abstract.txt"
    Description: Reads the plain text content of a file with .txt or .do (Stata do-file) extensions. This is the default reader if a specific file type is not recognized.
    Returns: The content of the file as a string.

3.  read_pdf:
    e.g. read_pdf: "data/study_Y/methods.pdf"
    Description: Extracts and reads the text content from a PDF (.pdf) file. INTELLIGENT HANDLING: If the PDF is > 15 pages, this tool automatically chunks and summarizes it to capture key methodologies, metrics, and results. If <= 15 pages, it returns the full text.
    Returns: The extracted text content of the PDF as a string.

4.  read_json:
    e.g. read_json: "data/study_Z/config.json"
    Description: Reads and parses a JSON (.json) file.
    Returns: The content of the JSON file as a Python dictionary (which will be converted to string representation for observation).
    
5. read_docx: 
    e.g. `read_docx: "data/study_Z/protocol.docx"`
    * Description: Extracts and reads the text content from a Microsoft Word (.docx) file.
    * Returns: The extracted text content of the file as a string.
    
6. read_log:
    e.g. `read_log: "data/study_Z/design.log"`
    * Description: Extracts and reads the text content from a log file. If a log is too long, a shorter version, where the full log is separated into chunks. Each chunk is summarized and then combined into a overall summary of log content. 
    * Returns: Full or summarized content of the log file.

7. read_image:
   e.g read_image: "data/study_T/image.png"
   Description: Take in an input image of type .png, .jpeg, .jpg, .webp, or .gif and describe in natural language what the image is about.
   Returns: Textual description of the provided image

8. Dataset Related Tools
   7a.  load_dataset:
    * e.g. `load_dataset: "data/study_A/patient_records.csv"` or  `load_dataset: "data/study_A/patient_records.xlsx"`
    * Description: Loads a dataset from a CSV or Excel file into memory for analysis. This function must be called successfully on a file path before any other `get_dataset_*` tools can be used on it.
    * Returns: A string confirming that the dataset was loaded successfully, or an error message if it failed.

   7b.  get_dataset_head:    
    * e.g. `get_dataset_head: "data/study_A/patient_records.csv"`
    * Description: Retrieves the first 5 rows of a previously loaded CSV dataset. This is useful for quickly inspecting the data's structure, column names, and sample values.
    * Returns: A string containing the first 'n' rows of the dataset in a comma-separated format.

   7c.  get_dataset_shape:
    * e.g. `get_dataset_shape: "data/study_A/patient_records.csv"`
    * Description: Gets the dimensions (number of rows, number of columns) of a previously loaded CSV dataset.
    * Returns: A string representing a tuple, for example, "(150, 4)", indicating (rows, columns).

   7d.  get_dataset_description:
    * e.g. `get_dataset_description: "data/study_A/patient_records.csv"`
    * Description: Calculates descriptive statistics for the numerical columns of a loaded CSV dataset. This includes count, mean, standard deviation, min, max, and percentiles.
    * Returns: A string containing a summary table of the descriptive statistics.

9.  get_dataset_info:
    
    * e.g. `get_dataset_info: "data/study_A/patient_records.csv"`
    * Description: Provides a concise technical summary of a loaded CSV dataset, including column names, data types (e.g., integer, float), and the number of non-missing values for each column.
    * Returns: A string containing the full summary information of the dataset.
    
10. ask_human_input:
    * e.g. `ask_human_input: "Need access permission to download data, please download it and give me the path to the downloaded folder"`
    * Description: Asks a clarifying question to the human user and waits for their text response. Use this tool only when you are stuck, if the instructions are ambiguous, or if you need external information you cannot find in the files.
    * Returns: The human's raw text response as a string.

Remember, you don't have to read all provided files if you don't think they are necessary to fill out the required JSON.
""".strip()
